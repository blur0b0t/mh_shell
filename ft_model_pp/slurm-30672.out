got current job name=fts5
new job name=fts6
new job created with id: 30680
----------checking if gpu available on current job-----------------
no change     /home/common/miniconda3/condabin/conda
no change     /home/common/miniconda3/bin/conda
no change     /home/common/miniconda3/bin/conda-env
no change     /home/common/miniconda3/bin/activate
no change     /home/common/miniconda3/bin/deactivate
no change     /home/common/miniconda3/etc/profile.d/conda.sh
no change     /home/common/miniconda3/etc/fish/conf.d/conda.fish
no change     /home/common/miniconda3/shell/condabin/Conda.psm1
no change     /home/common/miniconda3/shell/condabin/conda-hook.ps1
no change     /home/common/miniconda3/lib/python3.10/site-packages/xontrib/conda.xsh
no change     /home/common/miniconda3/etc/profile.d/conda.csh
no change     /home/u131168/.bashrc
No action taken.
-------------------------------------------
users render freetier premium
 
:: initializing oneAPI environment ...
   slurm_script: BASH_VERSION = 5.1.16(1)-release
   args: Using "$@" for setvars.sh arguments: --force
:: advisor -- latest
:: ccl -- latest
:: compiler -- latest
:: dal -- latest
:: debugger -- latest
:: dev-utilities -- latest
:: dnnl -- latest
:: dpcpp-ct -- latest
:: dpl -- latest
:: embree -- latest
:: inspector -- latest
:: intelpython -- latest

CommandNotFoundError: Your shell has not been properly configured to use 'conda deactivate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.



CommandNotFoundError: Your shell has not been properly configured to use 'conda deactivate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


:: ipp -- latest
:: ippcp -- latest
:: ispc -- latest
:: itac -- latest
:: mkl -- latest
:: modelzoo -- latest
:: modin -- latest
:: mpi -- latest
:: neural-compressor -- latest
:: oidn -- latest
:: openpgl -- latest
:: openvkl -- latest
:: ospray -- latest
:: ospray_studio -- latest
:: pytorch -- latest
:: rkcommon -- latest
:: rkutil -- latest
:: tbb -- latest
:: tensorflow -- latest
:: vtune -- latest
:: oneAPI environment initialized ::
 
Warning: ONEAPI_DEVICE_SELECTOR environment variable is set to opencl:cpu;opencl:fpga;level_zero:3.
To see the correct device id, please unset ONEAPI_DEVICE_SELECTOR.

[opencl:cpu:0] Intel(R) OpenCL, Intel(R) Xeon(R) Platinum 8480+ 3.0 [2023.16.7.0.21_160000]
[opencl:acc:1] Intel(R) FPGA Emulation Platform for OpenCL(TM), Intel(R) FPGA Emulation Device 1.2 [2023.16.7.0.21_160000]
[opencl:cpu:2] Intel(R) OpenCL, Intel(R) Xeon(R) Platinum 8480+ 3.0 [2023.16.7.0.21_160000]
[ext_oneapi_level_zero:gpu:0] Intel(R) Level-Zero, Intel(R) Data Center GPU Max 1100 1.3 [1.3.26516]
Warning: ONEAPI_DEVICE_SELECTOR environment variable is set to opencl:cpu;opencl:fpga;level_zero:3.
To see the correct device id, please unset ONEAPI_DEVICE_SELECTOR.

num_gpu=1\n
Warning: ONEAPI_DEVICE_SELECTOR environment variable is set to opencl:cpu;opencl:fpga;level_zero:3.
To see the correct device id, please unset ONEAPI_DEVICE_SELECTOR.

num_cpu=2\n
/var/spool/slurmd/job30672/slurm_script: line 36: [: missing `]'
-------------------------------------------
starting fine tuning model
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: datasets in /home/u131168/.local/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (2.14.5)
Requirement already satisfied: torch in /home/u131168/.local/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (2.1.0)
Requirement already satisfied: transformers>=4.32.0 in /home/u131168/.local/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (4.35.0.dev0)
Requirement already satisfied: sentencepiece in /home/u131168/.local/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (0.1.99)
Requirement already satisfied: peft in /home/u131168/.local/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (0.5.0)
Requirement already satisfied: evaluate in /home/u131168/.local/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (0.4.0)
Requirement already satisfied: nltk in /home/u131168/.local/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (3.8.1)
Requirement already satisfied: rouge_score in /home/u131168/.local/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (0.1.2)
Requirement already satisfied: einops in /home/u131168/.local/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (0.7.0)
Requirement already satisfied: numpy>=1.17 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 1)) (1.24.3)
Requirement already satisfied: pyarrow>=8.0.0 in /home/u131168/.local/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 1)) (13.0.0)
Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/u131168/.local/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 1)) (0.3.7)
Requirement already satisfied: pandas in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 1)) (2.0.3)
Requirement already satisfied: requests>=2.19.0 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 1)) (2.31.0)
Requirement already satisfied: tqdm>=4.62.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 1)) (4.65.0)
Requirement already satisfied: xxhash in /home/u131168/.local/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 1)) (3.4.1)
Requirement already satisfied: multiprocess in /home/u131168/.local/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 1)) (0.70.15)
Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /home/u131168/.local/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 1)) (2023.6.0)
Requirement already satisfied: aiohttp in /home/u131168/.local/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 1)) (3.8.6)
Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /home/u131168/.local/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 1)) (0.17.3)
Requirement already satisfied: packaging in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 1)) (23.1)
Requirement already satisfied: pyyaml>=5.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from datasets->-r requirements.txt (line 1)) (6.0)
Requirement already satisfied: filelock in /home/u131168/.local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 2)) (3.12.4)
Requirement already satisfied: typing-extensions in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from torch->-r requirements.txt (line 2)) (4.6.3)
Requirement already satisfied: sympy in /home/u131168/.local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 2)) (1.12)
Requirement already satisfied: networkx in /home/u131168/.local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 2)) (3.1)
Requirement already satisfied: jinja2 in /home/u131168/.local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 2)) (3.1.2)
Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/u131168/.local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 2)) (12.1.105)
Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/u131168/.local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 2)) (12.1.105)
Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/u131168/.local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 2)) (12.1.105)
Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/u131168/.local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 2)) (8.9.2.26)
Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/u131168/.local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 2)) (12.1.3.1)
Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/u131168/.local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 2)) (11.0.2.54)
Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/u131168/.local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 2)) (10.3.2.106)
Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/u131168/.local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 2)) (11.4.5.107)
Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/u131168/.local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 2)) (12.1.0.106)
Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/u131168/.local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 2)) (2.18.1)
Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/u131168/.local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 2)) (12.1.105)
Requirement already satisfied: triton==2.1.0 in /home/u131168/.local/lib/python3.9/site-packages (from torch->-r requirements.txt (line 2)) (2.1.0)
Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/u131168/.local/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 2)) (12.2.140)
Requirement already satisfied: regex!=2019.12.17 in /home/u131168/.local/lib/python3.9/site-packages (from transformers>=4.32.0->-r requirements.txt (line 3)) (2023.10.3)
Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/u131168/.local/lib/python3.9/site-packages (from transformers>=4.32.0->-r requirements.txt (line 3)) (0.14.1)
Requirement already satisfied: safetensors>=0.3.1 in /home/u131168/.local/lib/python3.9/site-packages (from transformers>=4.32.0->-r requirements.txt (line 3)) (0.4.0)
Requirement already satisfied: psutil in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from peft->-r requirements.txt (line 5)) (5.9.0)
Requirement already satisfied: accelerate in /home/u131168/.local/lib/python3.9/site-packages (from peft->-r requirements.txt (line 5)) (0.23.0)
Requirement already satisfied: responses<0.19 in /home/u131168/.local/lib/python3.9/site-packages (from evaluate->-r requirements.txt (line 6)) (0.18.0)
Requirement already satisfied: click in /home/u131168/.local/lib/python3.9/site-packages (from nltk->-r requirements.txt (line 7)) (8.1.7)
Requirement already satisfied: joblib in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from nltk->-r requirements.txt (line 7)) (1.2.0)
Requirement already satisfied: absl-py in /home/u131168/.local/lib/python3.9/site-packages (from rouge_score->-r requirements.txt (line 8)) (2.0.0)
Requirement already satisfied: six>=1.14.0 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from rouge_score->-r requirements.txt (line 8)) (1.16.0)
Requirement already satisfied: attrs>=17.3.0 in /home/u131168/.local/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (23.1.0)
Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (3.1.0)
Requirement already satisfied: multidict<7.0,>=4.5 in /home/u131168/.local/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (6.0.4)
Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/u131168/.local/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (4.0.3)
Requirement already satisfied: yarl<2.0,>=1.0 in /home/u131168/.local/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.9.2)
Requirement already satisfied: frozenlist>=1.1.1 in /home/u131168/.local/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.4.0)
Requirement already satisfied: aiosignal>=1.1.2 in /home/u131168/.local/lib/python3.9/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.3.1)
Requirement already satisfied: idna<4,>=2.5 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (2.0.3)
Requirement already satisfied: certifi>=2017.4.17 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (2023.7.22)
Requirement already satisfied: MarkupSafe>=2.0 in /home/u131168/.local/lib/python3.9/site-packages (from jinja2->torch->-r requirements.txt (line 2)) (2.1.3)
Requirement already satisfied: python-dateutil>=2.8.2 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2.8.2)
Requirement already satisfied: pytz>=2020.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2023.3)
Requirement already satisfied: tzdata>=2022.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2023.3)
Requirement already satisfied: mpmath>=0.19 in /home/u131168/.local/lib/python3.9/site-packages (from sympy->torch->-r requirements.txt (line 2)) (1.3.0)
Defaulting to user installation because normal site-packages is not writeable
Looking in links: https://developer.intel.com/ipex-whl-stable-cpu
Requirement already satisfied: oneccl_bind_pt in /home/u131168/.local/lib/python3.9/site-packages (2.0.0+cpu)
Defaulting to user installation because normal site-packages is not writeable
Collecting git+https://github.com/huggingface/transformers
  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-qo56dsjw
  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-qo56dsjw
  Resolved https://github.com/huggingface/transformers to commit 21dc5859421cf0d7d82d374b10f533611745a8c5
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Getting requirements to build wheel: started
  Getting requirements to build wheel: finished with status 'done'
  Preparing metadata (pyproject.toml): started
  Preparing metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: filelock in /home/u131168/.local/lib/python3.9/site-packages (from transformers==4.35.0.dev0) (3.12.4)
Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/u131168/.local/lib/python3.9/site-packages (from transformers==4.35.0.dev0) (0.17.3)
Requirement already satisfied: numpy>=1.17 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from transformers==4.35.0.dev0) (1.24.3)
Requirement already satisfied: packaging>=20.0 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from transformers==4.35.0.dev0) (23.1)
Requirement already satisfied: pyyaml>=5.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from transformers==4.35.0.dev0) (6.0)
Requirement already satisfied: regex!=2019.12.17 in /home/u131168/.local/lib/python3.9/site-packages (from transformers==4.35.0.dev0) (2023.10.3)
Requirement already satisfied: requests in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from transformers==4.35.0.dev0) (2.31.0)
Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/u131168/.local/lib/python3.9/site-packages (from transformers==4.35.0.dev0) (0.14.1)
Requirement already satisfied: safetensors>=0.3.1 in /home/u131168/.local/lib/python3.9/site-packages (from transformers==4.35.0.dev0) (0.4.0)
Requirement already satisfied: tqdm>=4.27 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from transformers==4.35.0.dev0) (4.65.0)
Requirement already satisfied: fsspec in /home/u131168/.local/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0.dev0) (2023.6.0)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0.dev0) (4.6.3)
Requirement already satisfied: charset-normalizer<4,>=2 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->transformers==4.35.0.dev0) (3.1.0)
Requirement already satisfied: idna<4,>=2.5 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->transformers==4.35.0.dev0) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->transformers==4.35.0.dev0) (2.0.3)
Requirement already satisfied: certifi>=2017.4.17 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->transformers==4.35.0.dev0) (2023.7.22)
Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: tokenizers in /home/u131168/.local/lib/python3.9/site-packages (0.14.1)
Requirement already satisfied: huggingface_hub<0.18,>=0.16.4 in /home/u131168/.local/lib/python3.9/site-packages (from tokenizers) (0.17.3)
Requirement already satisfied: filelock in /home/u131168/.local/lib/python3.9/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (3.12.4)
Requirement already satisfied: fsspec in /home/u131168/.local/lib/python3.9/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (2023.6.0)
Requirement already satisfied: requests in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (2.31.0)
Requirement already satisfied: tqdm>=4.42.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (4.65.0)
Requirement already satisfied: pyyaml>=5.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (6.0)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (4.6.3)
Requirement already satisfied: packaging>=20.9 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (23.1)
Requirement already satisfied: charset-normalizer<4,>=2 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (3.1.0)
Requirement already satisfied: idna<4,>=2.5 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (2.0.3)
Requirement already satisfied: certifi>=2017.4.17 in /opt/intel/oneapi/intelpython/python3.9/lib/python3.9/site-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (2023.7.22)
/home/u131168/mh_shell/ft_models/flan-t5-xl_mt5_v4/checkpoint-132900
Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)
10/15/2023 02:14:00 - WARNING - __main__ - Process rank: 0, device: cpu, n_gpu: 0distributed training: True, 16-bits training: False
10/15/2023 02:14:00 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=0,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=True,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=True,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/home/u131168/mh_shell/ft_models/flan-t5-xl_mt5_v4/runs/Oct15_02-14-00_idc-beta-batch-pvc-node-04,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=None,
mp_parameters=,
no_cuda=False,
num_train_epochs=1.0,
optim=adamw_torch,
optim_args=None,
output_dir=/home/u131168/mh_shell/ft_models/flan-t5-xl_mt5_v4/,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=2,
per_device_train_batch_size=2,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=[],
resume_from_checkpoint=/home/u131168/mh_shell/ft_models/flan-t5-xl_mt5_v4/checkpoint-132900,
run_name=/home/u131168/mh_shell/ft_models/flan-t5-xl_mt5_v4/,
save_on_each_node=False,
save_safetensors=False,
save_steps=100,
save_strategy=steps,
save_total_limit=2,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.03,
warmup_steps=0,
weight_decay=0.0,
)
/home/u131168/.local/lib/python3.9/site-packages/datasets/load.py:2089: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.
You can remove this warning by passing 'token=None' instead.
  warnings.warn(
Using custom data configuration default-fa31c8c0449167a3
10/15/2023 02:14:00 - INFO - datasets.builder - Using custom data configuration default-fa31c8c0449167a3
Loading Dataset Infos from /home/u131168/.local/lib/python3.9/site-packages/datasets/packaged_modules/csv
10/15/2023 02:14:00 - INFO - datasets.info - Loading Dataset Infos from /home/u131168/.local/lib/python3.9/site-packages/datasets/packaged_modules/csv
Generating dataset csv (/home/u131168/.cache/huggingface/datasets/csv/default-fa31c8c0449167a3/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)
10/15/2023 02:14:00 - INFO - datasets.builder - Generating dataset csv (/home/u131168/.cache/huggingface/datasets/csv/default-fa31c8c0449167a3/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)
Downloading and preparing dataset csv/default to /home/u131168/.cache/huggingface/datasets/csv/default-fa31c8c0449167a3/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...
10/15/2023 02:14:00 - INFO - datasets.builder - Downloading and preparing dataset csv/default to /home/u131168/.cache/huggingface/datasets/csv/default-fa31c8c0449167a3/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...
Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 15887.52it/s]
Downloading took 0.0 min
10/15/2023 02:14:00 - INFO - datasets.download.download_manager - Downloading took 0.0 min
Checksum Computation took 0.0 min
10/15/2023 02:14:00 - INFO - datasets.download.download_manager - Checksum Computation took 0.0 min
Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 49.51it/s]
Generating train split
10/15/2023 02:14:00 - INFO - datasets.builder - Generating train split
Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 20000 examples [00:00, 139232.32 examples/s]Generating train split: 40000 examples [00:00, 153413.88 examples/s]Generating train split: 60000 examples [00:00, 158632.86 examples/s]Generating train split: 80000 examples [00:00, 158679.95 examples/s]Generating train split: 100000 examples [00:00, 161986.14 examples/s]Generating train split: 120000 examples [00:00, 163218.24 examples/s]Generating train split: 140000 examples [00:00, 163285.48 examples/s]Generating train split: 160000 examples [00:00, 165157.64 examples/s]Generating train split: 180000 examples [00:01, 164197.58 examples/s]Generating train split: 200000 examples [00:01, 161653.57 examples/s]Generating train split: 220000 examples [00:01, 160248.56 examples/s]Generating train split: 240000 examples [00:01, 159010.29 examples/s]Generating train split: 260000 examples [00:01, 158669.65 examples/s]Generating train split: 280000 examples [00:01, 159397.44 examples/s]Generating train split: 300000 examples [00:01, 159160.87 examples/s]Generating train split: 320000 examples [00:01, 160483.52 examples/s]Generating train split: 340000 examples [00:02, 161383.45 examples/s]Generating train split: 360000 examples [00:02, 160039.86 examples/s]Generating train split: 380000 examples [00:02, 161874.67 examples/s]Generating train split: 400000 examples [00:02, 162461.85 examples/s]Generating train split: 420000 examples [00:02, 158759.12 examples/s]Generating train split: 440000 examples [00:02, 158729.90 examples/s]Generating train split: 460000 examples [00:02, 157921.18 examples/s]Generating train split: 480000 examples [00:03, 158637.22 examples/s]Generating train split: 500000 examples [00:03, 158152.27 examples/s]Generating train split: 520000 examples [00:03, 158716.92 examples/s]Generating train split: 540000 examples [00:03, 159506.59 examples/s]Generating train split: 560000 examples [00:03, 160393.38 examples/s]Generating train split: 580000 examples [00:03, 159435.20 examples/s]Generating train split: 600000 examples [00:03, 159039.48 examples/s]Generating train split: 620000 examples [00:03, 156705.98 examples/s]Generating train split: 640000 examples [00:04, 154431.82 examples/s]Generating train split: 660000 examples [00:04, 154844.51 examples/s]Generating train split: 680000 examples [00:04, 156742.64 examples/s]Generating train split: 689877 examples [00:05, 131733.99 examples/s]
Unable to verify splits sizes.
10/15/2023 02:14:05 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.
Dataset csv downloaded and prepared to /home/u131168/.cache/huggingface/datasets/csv/default-fa31c8c0449167a3/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.
10/15/2023 02:14:05 - INFO - datasets.builder - Dataset csv downloaded and prepared to /home/u131168/.cache/huggingface/datasets/csv/default-fa31c8c0449167a3/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.
[INFO|tokenization_utils_base.py:2053] 2023-10-15 02:14:07,670 >> loading file spiece.model from cache at /home/u131168/.cache/huggingface/hub/models--google--flan-t5-xl/snapshots/8772db7a7a11f7b08e6be7d7088f7a7fd4813bc5/spiece.model
[INFO|tokenization_utils_base.py:2053] 2023-10-15 02:14:07,671 >> loading file tokenizer.json from cache at /home/u131168/.cache/huggingface/hub/models--google--flan-t5-xl/snapshots/8772db7a7a11f7b08e6be7d7088f7a7fd4813bc5/tokenizer.json
[INFO|tokenization_utils_base.py:2053] 2023-10-15 02:14:07,671 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2053] 2023-10-15 02:14:07,671 >> loading file special_tokens_map.json from cache at /home/u131168/.cache/huggingface/hub/models--google--flan-t5-xl/snapshots/8772db7a7a11f7b08e6be7d7088f7a7fd4813bc5/special_tokens_map.json
[INFO|tokenization_utils_base.py:2053] 2023-10-15 02:14:07,671 >> loading file tokenizer_config.json from cache at /home/u131168/.cache/huggingface/hub/models--google--flan-t5-xl/snapshots/8772db7a7a11f7b08e6be7d7088f7a7fd4813bc5/tokenizer_config.json
Running tokenizer on train dataset:   0%|          | 0/689877 [00:00<?, ? examples/s]Caching processed dataset at /home/u131168/.cache/huggingface/datasets/csv/default-fa31c8c0449167a3/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-4585f4542b6fbcfc.arrow
10/15/2023 02:14:08 - INFO - datasets.arrow_dataset - Caching processed dataset at /home/u131168/.cache/huggingface/datasets/csv/default-fa31c8c0449167a3/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-4585f4542b6fbcfc.arrow
Running tokenizer on train dataset:   0%|          | 1000/689877 [00:00<03:23, 3382.03 examples/s]Running tokenizer on train dataset:   0%|          | 2000/689877 [00:00<03:10, 3606.55 examples/s]Running tokenizer on train dataset:   0%|          | 3000/689877 [00:00<03:03, 3739.17 examples/s]Running tokenizer on train dataset:   1%|          | 4000/689877 [00:01<02:59, 3822.90 examples/s]Running tokenizer on train dataset:   1%|          | 5000/689877 [00:01<02:58, 3836.45 examples/s]Running tokenizer on train dataset:   1%|          | 6000/689877 [00:01<02:57, 3860.30 examples/s]Running tokenizer on train dataset:   1%|          | 7000/689877 [00:01<02:55, 3887.13 examples/s]Running tokenizer on train dataset:   1%|          | 8000/689877 [00:02<02:55, 3891.25 examples/s]Running tokenizer on train dataset:   1%|▏         | 9000/689877 [00:02<02:55, 3871.75 examples/s]Running tokenizer on train dataset:   1%|▏         | 10000/689877 [00:02<02:54, 3891.41 examples/s]Running tokenizer on train dataset:   2%|▏         | 11000/689877 [00:02<02:54, 3899.64 examples/s]Running tokenizer on train dataset:   2%|▏         | 12000/689877 [00:03<02:58, 3796.22 examples/s]Running tokenizer on train dataset:   2%|▏         | 13000/689877 [00:03<02:57, 3818.47 examples/s]Running tokenizer on train dataset:   2%|▏         | 14000/689877 [00:03<02:55, 3848.36 examples/s]Running tokenizer on train dataset:   2%|▏         | 15000/689877 [00:03<02:53, 3880.64 examples/s]Running tokenizer on train dataset:   2%|▏         | 16000/689877 [00:04<02:53, 3885.43 examples/s]Running tokenizer on train dataset:   2%|▏         | 17000/689877 [00:04<02:52, 3892.31 examples/s]Running tokenizer on train dataset:   3%|▎         | 18000/689877 [00:04<02:52, 3903.60 examples/s]Running tokenizer on train dataset:   3%|▎         | 19000/689877 [00:04<02:51, 3911.70 examples/s]Running tokenizer on train dataset:   3%|▎         | 20000/689877 [00:05<02:52, 3886.36 examples/s]Running tokenizer on train dataset:   3%|▎         | 21000/689877 [00:05<02:51, 3893.05 examples/s]Running tokenizer on train dataset:   3%|▎         | 22000/689877 [00:05<02:50, 3909.75 examples/s]Running tokenizer on train dataset:   3%|▎         | 23000/689877 [00:05<02:51, 3897.33 examples/s]Running tokenizer on train dataset:   3%|▎         | 24000/689877 [00:06<02:50, 3894.59 examples/s]Running tokenizer on train dataset:   4%|▎         | 25000/689877 [00:06<02:50, 3889.86 examples/s]Running tokenizer on train dataset:   4%|▍         | 26000/689877 [00:06<02:50, 3892.78 examples/s]Running tokenizer on train dataset:   4%|▍         | 27000/689877 [00:06<02:50, 3892.60 examples/s]Running tokenizer on train dataset:   4%|▍         | 28000/689877 [00:07<02:49, 3902.22 examples/s]Running tokenizer on train dataset:   4%|▍         | 29000/689877 [00:07<02:49, 3905.23 examples/s]Running tokenizer on train dataset:   4%|▍         | 30000/689877 [00:07<02:49, 3895.91 examples/s]Running tokenizer on train dataset:   4%|▍         | 31000/689877 [00:08<02:49, 3878.17 examples/s]Running tokenizer on train dataset:   5%|▍         | 32000/689877 [00:08<02:48, 3894.59 examples/s]Running tokenizer on train dataset:   5%|▍         | 33000/689877 [00:08<02:47, 3917.77 examples/s]Running tokenizer on train dataset:   5%|▍         | 34000/689877 [00:08<02:48, 3896.20 examples/s]Running tokenizer on train dataset:   5%|▌         | 35000/689877 [00:09<02:48, 3882.58 examples/s]Running tokenizer on train dataset:   5%|▌         | 36000/689877 [00:09<02:47, 3893.04 examples/s]Running tokenizer on train dataset:   5%|▌         | 37000/689877 [00:09<02:46, 3912.08 examples/s]Running tokenizer on train dataset:   6%|▌         | 38000/689877 [00:09<02:47, 3896.91 examples/s]Running tokenizer on train dataset:   6%|▌         | 39000/689877 [00:10<02:46, 3912.72 examples/s]Running tokenizer on train dataset:   6%|▌         | 40000/689877 [00:10<02:46, 3902.62 examples/s]Running tokenizer on train dataset:   6%|▌         | 41000/689877 [00:10<02:46, 3901.61 examples/s]Running tokenizer on train dataset:   6%|▌         | 42000/689877 [00:10<02:46, 3889.51 examples/s]Running tokenizer on train dataset:   6%|▌         | 43000/689877 [00:11<02:45, 3904.83 examples/s]Running tokenizer on train dataset:   6%|▋         | 44000/689877 [00:11<02:45, 3908.54 examples/s]Running tokenizer on train dataset:   7%|▋         | 45000/689877 [00:11<02:45, 3890.46 examples/s]Running tokenizer on train dataset:   7%|▋         | 46000/689877 [00:11<02:46, 3878.40 examples/s]Running tokenizer on train dataset:   7%|▋         | 47000/689877 [00:12<02:45, 3889.34 examples/s]Running tokenizer on train dataset:   7%|▋         | 48000/689877 [00:12<02:44, 3905.32 examples/s]Running tokenizer on train dataset:   7%|▋         | 49000/689877 [00:12<02:44, 3894.98 examples/s]Running tokenizer on train dataset:   7%|▋         | 50000/689877 [00:12<02:43, 3912.11 examples/s]Running tokenizer on train dataset:   7%|▋         | 51000/689877 [00:13<02:42, 3919.75 examples/s]Running tokenizer on train dataset:   8%|▊         | 52000/689877 [00:13<02:43, 3911.14 examples/s]Running tokenizer on train dataset:   8%|▊         | 53000/689877 [00:13<02:44, 3883.19 examples/s]Running tokenizer on train dataset:   8%|▊         | 54000/689877 [00:13<02:42, 3902.20 examples/s]Running tokenizer on train dataset:   8%|▊         | 55000/689877 [00:14<02:41, 3921.00 examples/s]Running tokenizer on train dataset:   8%|▊         | 56000/689877 [00:14<02:42, 3898.35 examples/s]Running tokenizer on train dataset:   8%|▊         | 57000/689877 [00:14<02:42, 3902.56 examples/s]Running tokenizer on train dataset:   8%|▊         | 58000/689877 [00:14<02:41, 3909.11 examples/s]Running tokenizer on train dataset:   9%|▊         | 59000/689877 [00:15<02:40, 3920.87 examples/s]Running tokenizer on train dataset:   9%|▊         | 60000/689877 [00:15<02:42, 3873.24 examples/s]Running tokenizer on train dataset:   9%|▉         | 61000/689877 [00:15<02:41, 3891.60 examples/s]Running tokenizer on train dataset:   9%|▉         | 62000/689877 [00:15<02:40, 3901.23 examples/s]Running tokenizer on train dataset:   9%|▉         | 63000/689877 [00:16<02:41, 3891.93 examples/s]Running tokenizer on train dataset:   9%|▉         | 64000/689877 [00:16<02:41, 3873.65 examples/s]Running tokenizer on train dataset:   9%|▉         | 65000/689877 [00:16<02:40, 3890.99 examples/s]Running tokenizer on train dataset:  10%|▉         | 66000/689877 [00:16<02:39, 3914.46 examples/s]Running tokenizer on train dataset:  10%|▉         | 67000/689877 [00:17<02:39, 3894.89 examples/s]Running tokenizer on train dataset:  10%|▉         | 68000/689877 [00:17<02:40, 3882.15 examples/s]Running tokenizer on train dataset:  10%|█         | 69000/689877 [00:17<02:39, 3896.16 examples/s]Running tokenizer on train dataset:  10%|█         | 70000/689877 [00:18<02:43, 3798.15 examples/s]Running tokenizer on train dataset:  10%|█         | 71000/689877 [00:18<02:42, 3816.58 examples/s]Running tokenizer on train dataset:  10%|█         | 72000/689877 [00:18<02:40, 3851.64 examples/s]Running tokenizer on train dataset:  11%|█         | 73000/689877 [00:18<02:38, 3881.62 examples/s]Running tokenizer on train dataset:  11%|█         | 74000/689877 [00:19<02:38, 3887.90 examples/s]Running tokenizer on train dataset:  11%|█         | 75000/689877 [00:19<02:38, 3881.01 examples/s]Running tokenizer on train dataset:  11%|█         | 76000/689877 [00:19<02:38, 3878.15 examples/s]Running tokenizer on train dataset:  11%|█         | 77000/689877 [00:19<02:37, 3901.81 examples/s]Running tokenizer on train dataset:  11%|█▏        | 78000/689877 [00:20<02:37, 3889.64 examples/s]Running tokenizer on train dataset:  11%|█▏        | 79000/689877 [00:20<02:36, 3899.33 examples/s]Running tokenizer on train dataset:  12%|█▏        | 80000/689877 [00:20<02:36, 3902.67 examples/s]Running tokenizer on train dataset:  12%|█▏        | 81000/689877 [00:20<02:35, 3912.81 examples/s]Running tokenizer on train dataset:  12%|█▏        | 82000/689877 [00:21<02:36, 3895.82 examples/s]Running tokenizer on train dataset:  12%|█▏        | 83000/689877 [00:21<02:35, 3901.86 examples/s]Running tokenizer on train dataset:  12%|█▏        | 84000/689877 [00:21<02:34, 3914.88 examples/s]Running tokenizer on train dataset:  12%|█▏        | 85000/689877 [00:21<02:35, 3901.68 examples/s]Running tokenizer on train dataset:  12%|█▏        | 86000/689877 [00:22<02:35, 3884.35 examples/s]Running tokenizer on train dataset:  13%|█▎        | 87000/689877 [00:22<02:34, 3896.87 examples/s]Running tokenizer on train dataset:  13%|█▎        | 88000/689877 [00:22<02:33, 3913.76 examples/s]Running tokenizer on train dataset:  13%|█▎        | 89000/689877 [00:22<02:34, 3887.43 examples/s]Running tokenizer on train dataset:  13%|█▎        | 90000/689877 [00:23<02:34, 3888.64 examples/s]Running tokenizer on train dataset:  13%|█▎        | 91000/689877 [00:23<02:33, 3893.40 examples/s]Running tokenizer on train dataset:  13%|█▎        | 92000/689877 [00:23<02:33, 3899.58 examples/s]Running tokenizer on train dataset:  13%|█▎        | 93000/689877 [00:23<02:33, 3877.51 examples/s]Running tokenizer on train dataset:  14%|█▎        | 94000/689877 [00:24<02:32, 3897.40 examples/s]Running tokenizer on train dataset:  14%|█▍        | 95000/689877 [00:24<02:31, 3914.11 examples/s]Running tokenizer on train dataset:  14%|█▍        | 96000/689877 [00:24<02:32, 3895.65 examples/s]Running tokenizer on train dataset:  14%|█▍        | 97000/689877 [00:24<02:32, 3878.64 examples/s]Running tokenizer on train dataset:  14%|█▍        | 98000/689877 [00:25<02:31, 3895.56 examples/s]Running tokenizer on train dataset:  14%|█▍        | 99000/689877 [00:25<02:31, 3906.48 examples/s]Running tokenizer on train dataset:  14%|█▍        | 100000/689877 [00:25<02:31, 3891.52 examples/s]Running tokenizer on train dataset:  15%|█▍        | 101000/689877 [00:25<02:31, 3893.09 examples/s]Running tokenizer on train dataset:  15%|█▍        | 102000/689877 [00:26<02:30, 3902.18 examples/s]Running tokenizer on train dataset:  15%|█▍        | 103000/689877 [00:26<02:29, 3912.70 examples/s]Running tokenizer on train dataset:  15%|█▌        | 104000/689877 [00:26<02:30, 3893.89 examples/s]Running tokenizer on train dataset:  15%|█▌        | 105000/689877 [00:27<02:29, 3913.18 examples/s]Running tokenizer on train dataset:  15%|█▌        | 106000/689877 [00:27<02:28, 3926.99 examples/s]Running tokenizer on train dataset:  16%|█▌        | 107000/689877 [00:27<02:29, 3895.37 examples/s]Running tokenizer on train dataset:  16%|█▌        | 108000/689877 [00:27<02:29, 3892.27 examples/s]Running tokenizer on train dataset:  16%|█▌        | 109000/689877 [00:28<02:28, 3901.22 examples/s]Running tokenizer on train dataset:  16%|█▌        | 110000/689877 [00:28<02:28, 3913.56 examples/s]Running tokenizer on train dataset:  16%|█▌        | 111000/689877 [00:28<02:28, 3896.84 examples/s]Running tokenizer on train dataset:  16%|█▌        | 112000/689877 [00:28<02:28, 3903.73 examples/s]Running tokenizer on train dataset:  16%|█▋        | 113000/689877 [00:29<02:27, 3914.85 examples/s]Running tokenizer on train dataset:  17%|█▋        | 114000/689877 [00:29<02:26, 3921.07 examples/s]Running tokenizer on train dataset:  17%|█▋        | 115000/689877 [00:29<02:27, 3896.80 examples/s]Running tokenizer on train dataset:  17%|█▋        | 116000/689877 [00:29<02:26, 3910.06 examples/s]Running tokenizer on train dataset:  17%|█▋        | 117000/689877 [00:30<02:25, 3930.01 examples/s]Running tokenizer on train dataset:  17%|█▋        | 118000/689877 [00:30<02:26, 3908.40 examples/s]Running tokenizer on train dataset:  17%|█▋        | 119000/689877 [00:30<02:26, 3899.41 examples/s]Running tokenizer on train dataset:  17%|█▋        | 120000/689877 [00:30<02:26, 3896.97 examples/s]Running tokenizer on train dataset:  18%|█▊        | 121000/689877 [00:31<02:25, 3910.16 examples/s]Running tokenizer on train dataset:  18%|█▊        | 122000/689877 [00:31<02:25, 3901.60 examples/s]Running tokenizer on train dataset:  18%|█▊        | 123000/689877 [00:31<02:24, 3910.60 examples/s]Running tokenizer on train dataset:  18%|█▊        | 124000/689877 [00:31<02:24, 3913.87 examples/s]Running tokenizer on train dataset:  18%|█▊        | 125000/689877 [00:32<02:24, 3907.93 examples/s]Running tokenizer on train dataset:  18%|█▊        | 126000/689877 [00:32<02:24, 3893.02 examples/s]Running tokenizer on train dataset:  18%|█▊        | 127000/689877 [00:32<02:23, 3909.37 examples/s]Running tokenizer on train dataset:  19%|█▊        | 128000/689877 [00:32<02:25, 3870.92 examples/s]Running tokenizer on train dataset:  19%|█▊        | 129000/689877 [00:33<02:27, 3805.09 examples/s]Running tokenizer on train dataset:  19%|█▉        | 130000/689877 [00:33<02:26, 3830.11 examples/s]Running tokenizer on train dataset:  19%|█▉        | 131000/689877 [00:33<02:25, 3850.21 examples/s]Running tokenizer on train dataset:  19%|█▉        | 132000/689877 [00:33<02:23, 3885.72 examples/s]Running tokenizer on train dataset:  19%|█▉        | 133000/689877 [00:34<02:23, 3869.11 examples/s]Running tokenizer on train dataset:  19%|█▉        | 134000/689877 [00:34<02:22, 3889.97 examples/s]Running tokenizer on train dataset:  20%|█▉        | 135000/689877 [00:34<02:22, 3900.50 examples/s]Running tokenizer on train dataset:  20%|█▉        | 136000/689877 [00:34<02:21, 3902.21 examples/s]Running tokenizer on train dataset:  20%|█▉        | 137000/689877 [00:35<02:22, 3891.89 examples/s]Running tokenizer on train dataset:  20%|██        | 138000/689877 [00:35<02:21, 3907.86 examples/s]Running tokenizer on train dataset:  20%|██        | 139000/689877 [00:35<02:20, 3919.70 examples/s]Running tokenizer on train dataset:  20%|██        | 140000/689877 [00:35<02:21, 3898.24 examples/s]Running tokenizer on train dataset:  20%|██        | 141000/689877 [00:36<02:20, 3901.37 examples/s]Running tokenizer on train dataset:  21%|██        | 142000/689877 [00:36<02:20, 3911.71 examples/s]Running tokenizer on train dataset:  21%|██        | 143000/689877 [00:36<02:19, 3917.63 examples/s]Running tokenizer on train dataset:  21%|██        | 144000/689877 [00:37<02:19, 3899.99 examples/s]Running tokenizer on train dataset:  21%|██        | 145000/689877 [00:37<02:19, 3915.38 examples/s]Running tokenizer on train dataset:  21%|██        | 146000/689877 [00:37<02:18, 3923.49 examples/s]Running tokenizer on train dataset:  21%|██▏       | 147000/689877 [00:37<02:18, 3912.45 examples/s]Running tokenizer on train dataset:  21%|██▏       | 148000/689877 [00:38<02:19, 3882.68 examples/s]Running tokenizer on train dataset:  22%|██▏       | 149000/689877 [00:38<02:18, 3902.42 examples/s]Running tokenizer on train dataset:  22%|██▏       | 150000/689877 [00:38<02:17, 3914.27 examples/s]Running tokenizer on train dataset:  22%|██▏       | 151000/689877 [00:38<02:18, 3896.74 examples/s]Running tokenizer on train dataset:  22%|██▏       | 152000/689877 [00:39<02:17, 3901.13 examples/s]Running tokenizer on train dataset:  22%|██▏       | 153000/689877 [00:39<02:17, 3910.95 examples/s]Running tokenizer on train dataset:  22%|██▏       | 154000/689877 [00:39<02:16, 3919.10 examples/s]Running tokenizer on train dataset:  22%|██▏       | 155000/689877 [00:39<02:17, 3899.10 examples/s]Running tokenizer on train dataset:  23%|██▎       | 156000/689877 [00:40<02:16, 3909.39 examples/s]Running tokenizer on train dataset:  23%|██▎       | 157000/689877 [00:40<02:16, 3918.15 examples/s]Running tokenizer on train dataset:  23%|██▎       | 158000/689877 [00:40<02:15, 3912.89 examples/s]Running tokenizer on train dataset:  23%|██▎       | 159000/689877 [00:40<02:16, 3896.63 examples/s]Running tokenizer on train dataset:  23%|██▎       | 160000/689877 [00:41<02:15, 3900.06 examples/s]Running tokenizer on train dataset:  23%|██▎       | 161000/689877 [00:41<02:15, 3917.23 examples/s]Running tokenizer on train dataset:  23%|██▎       | 162000/689877 [00:41<02:15, 3892.26 examples/s]Running tokenizer on train dataset:  24%|██▎       | 163000/689877 [00:41<02:15, 3880.38 examples/s]Running tokenizer on train dataset:  24%|██▍       | 164000/689877 [00:42<02:15, 3891.63 examples/s]Running tokenizer on train dataset:  24%|██▍       | 165000/689877 [00:42<02:14, 3902.99 examples/s]Running tokenizer on train dataset:  24%|██▍       | 166000/689877 [00:42<02:14, 3887.37 examples/s]Running tokenizer on train dataset:  24%|██▍       | 167000/689877 [00:42<02:14, 3901.36 examples/s]Running tokenizer on train dataset:  24%|██▍       | 168000/689877 [00:43<02:13, 3913.74 examples/s]Running tokenizer on train dataset:  24%|██▍       | 169000/689877 [00:43<02:13, 3903.17 examples/s]Running tokenizer on train dataset:  25%|██▍       | 170000/689877 [00:43<02:13, 3888.30 examples/s]Running tokenizer on train dataset:  25%|██▍       | 171000/689877 [00:43<02:13, 3896.17 examples/s]Running tokenizer on train dataset:  25%|██▍       | 172000/689877 [00:44<02:12, 3904.74 examples/s]Running tokenizer on train dataset:  25%|██▌       | 173000/689877 [00:44<02:13, 3882.31 examples/s]Running tokenizer on train dataset:  25%|██▌       | 174000/689877 [00:44<02:12, 3891.66 examples/s]Running tokenizer on train dataset:  25%|██▌       | 175000/689877 [00:44<02:11, 3903.69 examples/s]Running tokenizer on train dataset:  26%|██▌       | 176000/689877 [00:45<02:11, 3912.00 examples/s]Running tokenizer on train dataset:  26%|██▌       | 177000/689877 [00:45<02:11, 3892.57 examples/s]Running tokenizer on train dataset:  26%|██▌       | 178000/689877 [00:45<02:10, 3907.76 examples/s]Running tokenizer on train dataset:  26%|██▌       | 179000/689877 [00:45<02:10, 3926.72 examples/s]Running tokenizer on train dataset:  26%|██▌       | 180000/689877 [00:46<02:10, 3914.35 examples/s]Running tokenizer on train dataset:  26%|██▌       | 181000/689877 [00:46<02:10, 3898.86 examples/s]Running tokenizer on train dataset:  26%|██▋       | 182000/689877 [00:46<02:09, 3913.47 examples/s]Running tokenizer on train dataset:  27%|██▋       | 183000/689877 [00:47<02:09, 3924.11 examples/s]Running tokenizer on train dataset:  27%|██▋       | 184000/689877 [00:47<02:09, 3894.02 examples/s]Running tokenizer on train dataset:  27%|██▋       | 185000/689877 [00:47<02:09, 3891.34 examples/s]Running tokenizer on train dataset:  27%|██▋       | 186000/689877 [00:47<02:09, 3902.27 examples/s]Running tokenizer on train dataset:  27%|██▋       | 187000/689877 [00:48<02:12, 3796.79 examples/s]Running tokenizer on train dataset:  27%|██▋       | 188000/689877 [00:48<02:11, 3812.39 examples/s]Running tokenizer on train dataset:  27%|██▋       | 189000/689877 [00:48<02:09, 3855.54 examples/s]Running tokenizer on train dataset:  28%|██▊       | 190000/689877 [00:48<02:08, 3883.38 examples/s]Running tokenizer on train dataset:  28%|██▊       | 191000/689877 [00:49<02:08, 3881.63 examples/s]Running tokenizer on train dataset:  28%|██▊       | 192000/689877 [00:49<02:08, 3880.65 examples/s]Running tokenizer on train dataset:  28%|██▊       | 193000/689877 [00:49<02:07, 3897.50 examples/s]Running tokenizer on train dataset:  28%|██▊       | 194000/689877 [00:49<02:06, 3909.67 examples/s]Running tokenizer on train dataset:  28%|██▊       | 195000/689877 [00:50<02:07, 3891.18 examples/s]Running tokenizer on train dataset:  28%|██▊       | 196000/689877 [00:50<02:06, 3894.97 examples/s]Running tokenizer on train dataset:  29%|██▊       | 197000/689877 [00:50<02:06, 3903.82 examples/s]Running tokenizer on train dataset:  29%|██▊       | 198000/689877 [00:50<02:05, 3905.45 examples/s]Running tokenizer on train dataset:  29%|██▉       | 199000/689877 [00:51<02:06, 3889.52 examples/s]Running tokenizer on train dataset:  29%|██▉       | 200000/689877 [00:51<02:05, 3908.40 examples/s]Running tokenizer on train dataset:  29%|██▉       | 201000/689877 [00:51<02:04, 3927.17 examples/s]Running tokenizer on train dataset:  29%|██▉       | 202000/689877 [00:51<02:05, 3902.18 examples/s]Running tokenizer on train dataset:  29%|██▉       | 203000/689877 [00:52<02:05, 3884.38 examples/s]Running tokenizer on train dataset:  30%|██▉       | 204000/689877 [00:52<02:05, 3884.39 examples/s]Running tokenizer on train dataset:  30%|██▉       | 205000/689877 [00:52<02:04, 3903.79 examples/s]Running tokenizer on train dataset:  30%|██▉       | 206000/689877 [00:52<02:04, 3875.19 examples/s]Running tokenizer on train dataset:  30%|███       | 207000/689877 [00:53<02:03, 3894.32 examples/s]Running tokenizer on train dataset:  30%|███       | 208000/689877 [00:53<02:03, 3900.10 examples/s]Running tokenizer on train dataset:  30%|███       | 209000/689877 [00:53<02:03, 3903.50 examples/s]Running tokenizer on train dataset:  30%|███       | 210000/689877 [00:53<02:03, 3878.91 examples/s]Running tokenizer on train dataset:  31%|███       | 211000/689877 [00:54<02:21, 3393.81 examples/s]Running tokenizer on train dataset:  31%|███       | 212000/689877 [00:54<02:15, 3539.14 examples/s]Running tokenizer on train dataset:  31%|███       | 213000/689877 [00:54<02:11, 3623.06 examples/s]Running tokenizer on train dataset:  31%|███       | 214000/689877 [00:55<02:08, 3690.06 examples/s]Running tokenizer on train dataset:  31%|███       | 215000/689877 [00:55<02:06, 3748.14 examples/s]Running tokenizer on train dataset:  31%|███▏      | 216000/689877 [00:55<02:04, 3801.64 examples/s]Running tokenizer on train dataset:  31%|███▏      | 217000/689877 [00:55<02:03, 3816.12 examples/s]Running tokenizer on train dataset:  32%|███▏      | 218000/689877 [00:56<02:02, 3848.00 examples/s]Running tokenizer on train dataset:  32%|███▏      | 219000/689877 [00:56<02:01, 3868.52 examples/s]Running tokenizer on train dataset:  32%|███▏      | 220000/689877 [00:56<02:01, 3880.60 examples/s]Running tokenizer on train dataset:  32%|███▏      | 221000/689877 [00:56<02:01, 3874.16 examples/s]Running tokenizer on train dataset:  32%|███▏      | 222000/689877 [00:57<02:00, 3893.31 examples/s]Running tokenizer on train dataset:  32%|███▏      | 223000/689877 [00:57<01:59, 3918.33 examples/s]Running tokenizer on train dataset:  32%|███▏      | 224000/689877 [00:57<01:59, 3899.10 examples/s]Running tokenizer on train dataset:  33%|███▎      | 225000/689877 [00:57<01:59, 3906.02 examples/s]Running tokenizer on train dataset:  33%|███▎      | 226000/689877 [00:58<01:58, 3905.18 examples/s]Running tokenizer on train dataset:  33%|███▎      | 227000/689877 [00:58<01:58, 3916.90 examples/s]Running tokenizer on train dataset:  33%|███▎      | 228000/689877 [00:58<01:58, 3882.61 examples/s]Running tokenizer on train dataset:  33%|███▎      | 229000/689877 [00:58<01:58, 3900.80 examples/s]Running tokenizer on train dataset:  33%|███▎      | 230000/689877 [00:59<01:57, 3914.01 examples/s]Running tokenizer on train dataset:  33%|███▎      | 231000/689877 [00:59<01:57, 3912.27 examples/s]Running tokenizer on train dataset:  34%|███▎      | 232000/689877 [00:59<01:57, 3898.77 examples/s]Running tokenizer on train dataset:  34%|███▍      | 233000/689877 [00:59<01:57, 3904.12 examples/s]Running tokenizer on train dataset:  34%|███▍      | 234000/689877 [01:00<01:56, 3918.37 examples/s]Running tokenizer on train dataset:  34%|███▍      | 235000/689877 [01:00<01:56, 3899.66 examples/s]Running tokenizer on train dataset:  34%|███▍      | 236000/689877 [01:00<01:56, 3904.64 examples/s]Running tokenizer on train dataset:  34%|███▍      | 237000/689877 [01:01<01:55, 3910.36 examples/s]Running tokenizer on train dataset:  34%|███▍      | 238000/689877 [01:01<01:55, 3923.39 examples/s]Running tokenizer on train dataset:  35%|███▍      | 239000/689877 [01:01<01:55, 3903.65 examples/s]Running tokenizer on train dataset:  35%|███▍      | 240000/689877 [01:01<01:54, 3917.15 examples/s]Running tokenizer on train dataset:  35%|███▍      | 241000/689877 [01:02<01:54, 3925.86 examples/s]Running tokenizer on train dataset:  35%|███▌      | 242000/689877 [01:02<01:54, 3918.40 examples/s]Running tokenizer on train dataset:  35%|███▌      | 243000/689877 [01:02<01:54, 3904.31 examples/s]Running tokenizer on train dataset:  35%|███▌      | 244000/689877 [01:02<01:54, 3907.52 examples/s]Running tokenizer on train dataset:  36%|███▌      | 245000/689877 [01:03<01:56, 3805.78 examples/s]Running tokenizer on train dataset:  36%|███▌      | 246000/689877 [01:03<01:56, 3816.47 examples/s]Running tokenizer on train dataset:  36%|███▌      | 247000/689877 [01:03<01:55, 3847.33 examples/s]Running tokenizer on train dataset:  36%|███▌      | 248000/689877 [01:03<01:54, 3865.77 examples/s]Running tokenizer on train dataset:  36%|███▌      | 249000/689877 [01:04<01:53, 3886.46 examples/s]Running tokenizer on train dataset:  36%|███▌      | 250000/689877 [01:04<01:53, 3876.60 examples/s]Running tokenizer on train dataset:  36%|███▋      | 251000/689877 [01:04<01:52, 3899.01 examples/s]Running tokenizer on train dataset:  37%|███▋      | 252000/689877 [01:04<01:52, 3899.74 examples/s]Running tokenizer on train dataset:  37%|███▋      | 253000/689877 [01:05<01:52, 3900.33 examples/s]Running tokenizer on train dataset:  37%|███▋      | 254000/689877 [01:05<01:52, 3886.87 examples/s]Running tokenizer on train dataset:  37%|███▋      | 255000/689877 [01:05<01:51, 3898.06 examples/s]Running tokenizer on train dataset:  37%|███▋      | 256000/689877 [01:05<01:50, 3913.97 examples/s]Running tokenizer on train dataset:  37%|███▋      | 257000/689877 [01:06<01:51, 3894.49 examples/s]Running tokenizer on train dataset:  37%|███▋      | 258000/689877 [01:06<01:50, 3899.92 examples/s]Running tokenizer on train dataset:  38%|███▊      | 259000/689877 [01:06<01:50, 3908.24 examples/s]Running tokenizer on train dataset:  38%|███▊      | 260000/689877 [01:06<01:49, 3918.28 examples/s]Running tokenizer on train dataset:  38%|███▊      | 261000/689877 [01:07<01:49, 3898.90 examples/s]Running tokenizer on train dataset:  38%|███▊      | 262000/689877 [01:07<01:49, 3915.43 examples/s]Running tokenizer on train dataset:  38%|███▊      | 263000/689877 [01:07<01:48, 3928.19 examples/s]Running tokenizer on train dataset:  38%|███▊      | 264000/689877 [01:07<01:48, 3916.19 examples/s]Running tokenizer on train dataset:  38%|███▊      | 265000/689877 [01:08<01:49, 3894.87 examples/s]Running tokenizer on train dataset:  39%|███▊      | 266000/689877 [01:08<01:48, 3906.42 examples/s]Running tokenizer on train dataset:  39%|███▊      | 267000/689877 [01:08<01:47, 3919.89 examples/s]Running tokenizer on train dataset:  39%|███▉      | 268000/689877 [01:08<01:48, 3903.35 examples/s]Running tokenizer on train dataset:  39%|███▉      | 269000/689877 [01:09<01:47, 3899.56 examples/s]Running tokenizer on train dataset:  39%|███▉      | 270000/689877 [01:09<01:47, 3911.84 examples/s]Running tokenizer on train dataset:  39%|███▉      | 271000/689877 [01:09<01:46, 3919.40 examples/s]Running tokenizer on train dataset:  39%|███▉      | 272000/689877 [01:09<01:47, 3897.00 examples/s]Running tokenizer on train dataset:  40%|███▉      | 273000/689877 [01:10<01:46, 3914.46 examples/s]Running tokenizer on train dataset:  40%|███▉      | 274000/689877 [01:10<01:45, 3926.64 examples/s]Running tokenizer on train dataset:  40%|███▉      | 275000/689877 [01:10<01:46, 3902.50 examples/s]Running tokenizer on train dataset:  40%|████      | 276000/689877 [01:11<01:46, 3893.79 examples/s]Running tokenizer on train dataset:  40%|████      | 277000/689877 [01:11<01:45, 3906.40 examples/s]Running tokenizer on train dataset:  40%|████      | 278000/689877 [01:11<01:45, 3918.90 examples/s]Running tokenizer on train dataset:  40%|████      | 279000/689877 [01:11<01:45, 3906.32 examples/s]Running tokenizer on train dataset:  41%|████      | 280000/689877 [01:12<01:44, 3908.03 examples/s]Running tokenizer on train dataset:  41%|████      | 281000/689877 [01:12<01:44, 3901.61 examples/s]Running tokenizer on train dataset:  41%|████      | 282000/689877 [01:12<01:44, 3904.44 examples/s]Running tokenizer on train dataset:  41%|████      | 283000/689877 [01:12<01:44, 3888.01 examples/s]Running tokenizer on train dataset:  41%|████      | 284000/689877 [01:13<01:44, 3897.67 examples/s]Running tokenizer on train dataset:  41%|████▏     | 285000/689877 [01:13<01:43, 3918.85 examples/s]Running tokenizer on train dataset:  41%|████▏     | 286000/689877 [01:13<01:43, 3894.38 examples/s]Running tokenizer on train dataset:  42%|████▏     | 287000/689877 [01:13<01:43, 3884.03 examples/s]Running tokenizer on train dataset:  42%|████▏     | 288000/689877 [01:14<01:43, 3892.89 examples/s]Running tokenizer on train dataset:  42%|████▏     | 289000/689877 [01:14<01:42, 3906.03 examples/s]Running tokenizer on train dataset:  42%|████▏     | 290000/689877 [01:14<01:42, 3888.86 examples/s]Running tokenizer on train dataset:  42%|████▏     | 291000/689877 [01:14<01:42, 3894.85 examples/s]Running tokenizer on train dataset:  42%|████▏     | 292000/689877 [01:15<01:41, 3900.76 examples/s]Running tokenizer on train dataset:  42%|████▏     | 293000/689877 [01:15<01:41, 3906.10 examples/s]Running tokenizer on train dataset:  43%|████▎     | 294000/689877 [01:15<01:41, 3889.05 examples/s]Running tokenizer on train dataset:  43%|████▎     | 295000/689877 [01:15<01:41, 3899.85 examples/s]Running tokenizer on train dataset:  43%|████▎     | 296000/689877 [01:16<01:40, 3916.21 examples/s]Running tokenizer on train dataset:  43%|████▎     | 297000/689877 [01:16<01:40, 3892.63 examples/s]Running tokenizer on train dataset:  43%|████▎     | 298000/689877 [01:16<01:40, 3891.50 examples/s]Running tokenizer on train dataset:  43%|████▎     | 299000/689877 [01:16<01:40, 3903.36 examples/s]Running tokenizer on train dataset:  43%|████▎     | 300000/689877 [01:17<01:39, 3922.22 examples/s]Running tokenizer on train dataset:  44%|████▎     | 301000/689877 [01:17<01:39, 3907.04 examples/s]Running tokenizer on train dataset:  44%|████▍     | 302000/689877 [01:17<01:38, 3918.66 examples/s]Running tokenizer on train dataset:  44%|████▍     | 303000/689877 [01:17<01:40, 3845.56 examples/s]Running tokenizer on train dataset:  44%|████▍     | 304000/689877 [01:18<01:40, 3835.42 examples/s]Running tokenizer on train dataset:  44%|████▍     | 305000/689877 [01:18<01:40, 3844.93 examples/s]Running tokenizer on train dataset:  44%|████▍     | 306000/689877 [01:18<01:38, 3881.00 examples/s]Running tokenizer on train dataset:  45%|████▍     | 307000/689877 [01:18<01:37, 3908.71 examples/s]Running tokenizer on train dataset:  45%|████▍     | 308000/689877 [01:19<01:38, 3891.78 examples/s]Running tokenizer on train dataset:  45%|████▍     | 309000/689877 [01:19<01:37, 3888.39 examples/s]Running tokenizer on train dataset:  45%|████▍     | 310000/689877 [01:19<01:37, 3893.92 examples/s]Running tokenizer on train dataset:  45%|████▌     | 311000/689877 [01:19<01:36, 3906.51 examples/s]Running tokenizer on train dataset:  45%|████▌     | 312000/689877 [01:20<01:37, 3893.02 examples/s]Running tokenizer on train dataset:  45%|████▌     | 313000/689877 [01:20<01:36, 3904.78 examples/s]Running tokenizer on train dataset:  46%|████▌     | 314000/689877 [01:20<01:35, 3919.06 examples/s]Running tokenizer on train dataset:  46%|████▌     | 315000/689877 [01:21<01:35, 3921.24 examples/s]Running tokenizer on train dataset:  46%|████▌     | 316000/689877 [01:21<01:35, 3906.49 examples/s]Running tokenizer on train dataset:  46%|████▌     | 317000/689877 [01:21<01:35, 3916.06 examples/s]Running tokenizer on train dataset:  46%|████▌     | 318000/689877 [01:21<01:34, 3928.08 examples/s]Running tokenizer on train dataset:  46%|████▌     | 319000/689877 [01:22<01:34, 3908.53 examples/s]Running tokenizer on train dataset:  46%|████▋     | 320000/689877 [01:22<01:34, 3914.82 examples/s]Running tokenizer on train dataset:  47%|████▋     | 321000/689877 [01:22<01:34, 3913.90 examples/s]Running tokenizer on train dataset:  47%|████▋     | 322000/689877 [01:22<01:33, 3914.74 examples/s]Running tokenizer on train dataset:  47%|████▋     | 323000/689877 [01:23<01:34, 3901.09 examples/s]Running tokenizer on train dataset:  47%|████▋     | 324000/689877 [01:23<01:45, 3471.78 examples/s]Running tokenizer on train dataset:  47%|████▋     | 325000/689877 [01:23<01:41, 3592.33 examples/s]Running tokenizer on train dataset:  47%|████▋     | 326000/689877 [01:23<01:38, 3678.71 examples/s]Running tokenizer on train dataset:  47%|████▋     | 327000/689877 [01:24<01:37, 3729.79 examples/s]Running tokenizer on train dataset:  48%|████▊     | 328000/689877 [01:24<01:35, 3785.22 examples/s]Running tokenizer on train dataset:  48%|████▊     | 329000/689877 [01:24<01:34, 3831.73 examples/s]Running tokenizer on train dataset:  48%|████▊     | 330000/689877 [01:24<01:36, 3745.83 examples/s]Running tokenizer on train dataset:  48%|████▊     | 331000/689877 [01:25<01:34, 3785.61 examples/s]Running tokenizer on train dataset:  48%|████▊     | 332000/689877 [01:25<01:33, 3819.50 examples/s]Running tokenizer on train dataset:  48%|████▊     | 333000/689877 [01:25<01:32, 3837.98 examples/s]Running tokenizer on train dataset:  48%|████▊     | 334000/689877 [01:26<01:32, 3837.32 examples/s]Running tokenizer on train dataset:  49%|████▊     | 335000/689877 [01:26<01:31, 3866.38 examples/s]Running tokenizer on train dataset:  49%|████▊     | 336000/689877 [01:26<01:30, 3889.99 examples/s]Running tokenizer on train dataset:  49%|████▉     | 337000/689877 [01:26<01:30, 3885.84 examples/s]Running tokenizer on train dataset:  49%|████▉     | 338000/689877 [01:27<01:30, 3873.83 examples/s]Running tokenizer on train dataset:  49%|████▉     | 339000/689877 [01:27<01:30, 3885.70 examples/s]Running tokenizer on train dataset:  49%|████▉     | 340000/689877 [01:27<01:29, 3902.65 examples/s]Running tokenizer on train dataset:  49%|████▉     | 341000/689877 [01:27<01:29, 3883.24 examples/s]Running tokenizer on train dataset:  50%|████▉     | 342000/689877 [01:28<01:29, 3887.01 examples/s]Running tokenizer on train dataset:  50%|████▉     | 343000/689877 [01:28<01:28, 3903.55 examples/s]Running tokenizer on train dataset:  50%|████▉     | 344000/689877 [01:28<01:28, 3890.22 examples/s]Running tokenizer on train dataset:  50%|█████     | 345000/689877 [01:28<01:29, 3863.35 examples/s]Running tokenizer on train dataset:  50%|█████     | 346000/689877 [01:29<01:28, 3881.64 examples/s]Running tokenizer on train dataset:  50%|█████     | 347000/689877 [01:29<01:27, 3901.35 examples/s]Running tokenizer on train dataset:  50%|█████     | 348000/689877 [01:29<01:27, 3894.48 examples/s]Running tokenizer on train dataset:  51%|█████     | 349000/689877 [01:29<01:28, 3872.01 examples/s]Running tokenizer on train dataset:  51%|█████     | 350000/689877 [01:30<01:27, 3881.67 examples/s]Running tokenizer on train dataset:  51%|█████     | 351000/689877 [01:30<01:26, 3896.11 examples/s]Running tokenizer on train dataset:  51%|█████     | 352000/689877 [01:30<01:26, 3886.85 examples/s]Running tokenizer on train dataset:  51%|█████     | 353000/689877 [01:30<01:26, 3884.92 examples/s]Running tokenizer on train dataset:  51%|█████▏    | 354000/689877 [01:31<01:26, 3894.40 examples/s]Running tokenizer on train dataset:  51%|█████▏    | 355000/689877 [01:31<01:25, 3898.85 examples/s]Running tokenizer on train dataset:  52%|█████▏    | 356000/689877 [01:31<01:26, 3873.13 examples/s]Running tokenizer on train dataset:  52%|█████▏    | 357000/689877 [01:31<01:25, 3893.67 examples/s]Running tokenizer on train dataset:  52%|█████▏    | 358000/689877 [01:32<01:24, 3906.95 examples/s]Running tokenizer on train dataset:  52%|█████▏    | 359000/689877 [01:32<01:24, 3897.99 examples/s]Running tokenizer on train dataset:  52%|█████▏    | 360000/689877 [01:32<01:24, 3887.08 examples/s]Running tokenizer on train dataset:  52%|█████▏    | 361000/689877 [01:32<01:27, 3771.79 examples/s]Running tokenizer on train dataset:  52%|█████▏    | 362000/689877 [01:33<01:25, 3816.52 examples/s]Running tokenizer on train dataset:  53%|█████▎    | 363000/689877 [01:33<01:25, 3821.99 examples/s]Running tokenizer on train dataset:  53%|█████▎    | 364000/689877 [01:33<01:24, 3843.83 examples/s]Running tokenizer on train dataset:  53%|█████▎    | 365000/689877 [01:34<01:24, 3863.74 examples/s]Running tokenizer on train dataset:  53%|█████▎    | 366000/689877 [01:34<01:23, 3876.08 examples/s]Running tokenizer on train dataset:  53%|█████▎    | 367000/689877 [01:34<01:23, 3865.26 examples/s]Running tokenizer on train dataset:  53%|█████▎    | 368000/689877 [01:34<01:22, 3886.03 examples/s]Running tokenizer on train dataset:  53%|█████▎    | 369000/689877 [01:35<01:22, 3902.17 examples/s]Running tokenizer on train dataset:  54%|█████▎    | 370000/689877 [01:35<01:22, 3887.75 examples/s]Running tokenizer on train dataset:  54%|█████▍    | 371000/689877 [01:35<01:22, 3879.03 examples/s]Running tokenizer on train dataset:  54%|█████▍    | 372000/689877 [01:35<01:21, 3889.71 examples/s]Running tokenizer on train dataset:  54%|█████▍    | 373000/689877 [01:36<01:21, 3898.38 examples/s]Running tokenizer on train dataset:  54%|█████▍    | 374000/689877 [01:36<01:21, 3886.19 examples/s]Running tokenizer on train dataset:  54%|█████▍    | 375000/689877 [01:36<01:20, 3895.88 examples/s]Running tokenizer on train dataset:  55%|█████▍    | 376000/689877 [01:36<01:20, 3896.96 examples/s]Running tokenizer on train dataset:  55%|█████▍    | 377000/689877 [01:37<01:20, 3904.05 examples/s]Running tokenizer on train dataset:  55%|█████▍    | 378000/689877 [01:37<01:20, 3876.60 examples/s]Running tokenizer on train dataset:  55%|█████▍    | 379000/689877 [01:37<01:19, 3895.37 examples/s]Running tokenizer on train dataset:  55%|█████▌    | 380000/689877 [01:37<01:19, 3908.15 examples/s]Running tokenizer on train dataset:  55%|█████▌    | 381000/689877 [01:38<01:19, 3889.57 examples/s]Running tokenizer on train dataset:  55%|█████▌    | 382000/689877 [01:38<01:19, 3885.68 examples/s]Running tokenizer on train dataset:  56%|█████▌    | 383000/689877 [01:38<01:18, 3889.19 examples/s]Running tokenizer on train dataset:  56%|█████▌    | 384000/689877 [01:38<01:18, 3898.33 examples/s]Running tokenizer on train dataset:  56%|█████▌    | 385000/689877 [01:39<01:18, 3889.31 examples/s]Running tokenizer on train dataset:  56%|█████▌    | 386000/689877 [01:39<01:17, 3899.48 examples/s]Running tokenizer on train dataset:  56%|█████▌    | 387000/689877 [01:39<01:17, 3899.81 examples/s]Running tokenizer on train dataset:  56%|█████▌    | 388000/689877 [01:39<01:17, 3890.74 examples/s]Running tokenizer on train dataset:  56%|█████▋    | 389000/689877 [01:40<01:17, 3879.51 examples/s]Running tokenizer on train dataset:  57%|█████▋    | 390000/689877 [01:40<01:16, 3901.61 examples/s]Running tokenizer on train dataset:  57%|█████▋    | 391000/689877 [01:40<01:16, 3913.34 examples/s]Running tokenizer on train dataset:  57%|█████▋    | 392000/689877 [01:40<01:16, 3885.05 examples/s]Running tokenizer on train dataset:  57%|█████▋    | 393000/689877 [01:41<01:16, 3875.89 examples/s]Running tokenizer on train dataset:  57%|█████▋    | 394000/689877 [01:41<01:16, 3889.27 examples/s]Running tokenizer on train dataset:  57%|█████▋    | 395000/689877 [01:41<01:15, 3902.27 examples/s]Running tokenizer on train dataset:  57%|█████▋    | 396000/689877 [01:41<01:15, 3883.28 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 397000/689877 [01:42<01:15, 3898.17 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 398000/689877 [01:42<01:14, 3908.72 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 399000/689877 [01:42<01:14, 3900.39 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 400000/689877 [01:42<01:14, 3882.79 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 401000/689877 [01:43<01:14, 3893.09 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 402000/689877 [01:43<01:13, 3907.26 examples/s]Running tokenizer on train dataset:  58%|█████▊    | 403000/689877 [01:43<01:13, 3882.47 examples/s]Running tokenizer on train dataset:  59%|█████▊    | 404000/689877 [01:44<01:13, 3887.91 examples/s]Running tokenizer on train dataset:  59%|█████▊    | 405000/689877 [01:44<01:13, 3893.95 examples/s]Running tokenizer on train dataset:  59%|█████▉    | 406000/689877 [01:44<01:12, 3905.38 examples/s]Running tokenizer on train dataset:  59%|█████▉    | 407000/689877 [01:44<01:12, 3886.03 examples/s]Running tokenizer on train dataset:  59%|█████▉    | 408000/689877 [01:45<01:12, 3897.02 examples/s]Running tokenizer on train dataset:  59%|█████▉    | 409000/689877 [01:45<01:11, 3903.96 examples/s]Running tokenizer on train dataset:  59%|█████▉    | 410000/689877 [01:45<01:11, 3895.62 examples/s]Running tokenizer on train dataset:  60%|█████▉    | 411000/689877 [01:45<01:11, 3877.35 examples/s]Running tokenizer on train dataset:  60%|█████▉    | 412000/689877 [01:46<01:11, 3887.34 examples/s]Running tokenizer on train dataset:  60%|█████▉    | 413000/689877 [01:46<01:11, 3889.65 examples/s]Running tokenizer on train dataset:  60%|██████    | 414000/689877 [01:46<01:11, 3874.66 examples/s]Running tokenizer on train dataset:  60%|██████    | 415000/689877 [01:46<01:10, 3879.66 examples/s]Running tokenizer on train dataset:  60%|██████    | 416000/689877 [01:47<01:10, 3890.11 examples/s]Running tokenizer on train dataset:  60%|██████    | 417000/689877 [01:47<01:09, 3900.29 examples/s]Running tokenizer on train dataset:  61%|██████    | 418000/689877 [01:47<01:10, 3875.65 examples/s]Running tokenizer on train dataset:  61%|██████    | 419000/689877 [01:47<01:10, 3839.76 examples/s]Running tokenizer on train dataset:  61%|██████    | 420000/689877 [01:48<01:11, 3777.34 examples/s]Running tokenizer on train dataset:  61%|██████    | 421000/689877 [01:48<01:10, 3807.67 examples/s]Running tokenizer on train dataset:  61%|██████    | 422000/689877 [01:48<01:10, 3809.43 examples/s]Running tokenizer on train dataset:  61%|██████▏   | 423000/689877 [01:48<01:09, 3831.97 examples/s]Running tokenizer on train dataset:  61%|██████▏   | 424000/689877 [01:49<01:08, 3867.16 examples/s]Running tokenizer on train dataset:  62%|██████▏   | 425000/689877 [01:49<01:08, 3862.04 examples/s]Running tokenizer on train dataset:  62%|██████▏   | 426000/689877 [01:49<01:08, 3868.46 examples/s]Running tokenizer on train dataset:  62%|██████▏   | 427000/689877 [01:49<01:07, 3877.86 examples/s]Running tokenizer on train dataset:  62%|██████▏   | 428000/689877 [01:50<01:07, 3889.04 examples/s]Running tokenizer on train dataset:  62%|██████▏   | 429000/689877 [01:50<01:07, 3870.65 examples/s]Running tokenizer on train dataset:  62%|██████▏   | 430000/689877 [01:50<01:06, 3883.97 examples/s]Running tokenizer on train dataset:  62%|██████▏   | 431000/689877 [01:50<01:06, 3898.33 examples/s]Running tokenizer on train dataset:  63%|██████▎   | 432000/689877 [01:51<01:06, 3892.80 examples/s]Running tokenizer on train dataset:  63%|██████▎   | 433000/689877 [01:51<01:06, 3876.45 examples/s]Running tokenizer on train dataset:  63%|██████▎   | 434000/689877 [01:51<01:05, 3880.59 examples/s]Running tokenizer on train dataset:  63%|██████▎   | 435000/689877 [01:52<01:05, 3896.18 examples/s]Running tokenizer on train dataset:  63%|██████▎   | 436000/689877 [01:52<01:05, 3881.96 examples/s]Running tokenizer on train dataset:  63%|██████▎   | 437000/689877 [01:52<01:05, 3878.76 examples/s]Running tokenizer on train dataset:  63%|██████▎   | 438000/689877 [01:52<01:04, 3889.89 examples/s]Running tokenizer on train dataset:  64%|██████▎   | 439000/689877 [01:53<01:04, 3904.90 examples/s]Running tokenizer on train dataset:  64%|██████▍   | 440000/689877 [01:53<01:04, 3875.13 examples/s]Running tokenizer on train dataset:  64%|██████▍   | 441000/689877 [01:53<01:04, 3886.78 examples/s]Running tokenizer on train dataset:  64%|██████▍   | 442000/689877 [01:53<01:03, 3900.61 examples/s]Running tokenizer on train dataset:  64%|██████▍   | 443000/689877 [01:54<01:03, 3885.34 examples/s]Running tokenizer on train dataset:  64%|██████▍   | 444000/689877 [01:54<01:03, 3877.89 examples/s]Running tokenizer on train dataset:  65%|██████▍   | 445000/689877 [01:54<01:02, 3887.65 examples/s]Running tokenizer on train dataset:  65%|██████▍   | 446000/689877 [01:54<01:02, 3899.07 examples/s]Running tokenizer on train dataset:  65%|██████▍   | 447000/689877 [01:55<01:02, 3890.42 examples/s]Running tokenizer on train dataset:  65%|██████▍   | 448000/689877 [01:55<01:02, 3885.22 examples/s]Running tokenizer on train dataset:  65%|██████▌   | 449000/689877 [01:55<01:01, 3896.67 examples/s]Running tokenizer on train dataset:  65%|██████▌   | 450000/689877 [01:55<01:01, 3901.07 examples/s]Running tokenizer on train dataset:  65%|██████▌   | 451000/689877 [01:56<01:01, 3881.73 examples/s]Running tokenizer on train dataset:  66%|██████▌   | 452000/689877 [01:56<01:01, 3892.31 examples/s]Running tokenizer on train dataset:  66%|██████▌   | 453000/689877 [01:56<01:00, 3906.97 examples/s]Running tokenizer on train dataset:  66%|██████▌   | 454000/689877 [01:56<01:00, 3888.36 examples/s]Running tokenizer on train dataset:  66%|██████▌   | 455000/689877 [01:57<01:00, 3877.79 examples/s]Running tokenizer on train dataset:  66%|██████▌   | 456000/689877 [01:57<01:00, 3876.58 examples/s]Running tokenizer on train dataset:  66%|██████▌   | 457000/689877 [01:57<00:59, 3889.93 examples/s]Running tokenizer on train dataset:  66%|██████▋   | 458000/689877 [01:57<00:59, 3866.91 examples/s]Running tokenizer on train dataset:  67%|██████▋   | 459000/689877 [01:58<00:59, 3879.46 examples/s]Running tokenizer on train dataset:  67%|██████▋   | 460000/689877 [01:58<00:59, 3887.42 examples/s]Running tokenizer on train dataset:  67%|██████▋   | 461000/689877 [01:58<00:58, 3890.79 examples/s]Running tokenizer on train dataset:  67%|██████▋   | 462000/689877 [01:58<00:58, 3873.47 examples/s]Running tokenizer on train dataset:  67%|██████▋   | 463000/689877 [01:59<00:58, 3890.62 examples/s]Running tokenizer on train dataset:  67%|██████▋   | 464000/689877 [01:59<00:57, 3909.04 examples/s]Running tokenizer on train dataset:  67%|██████▋   | 465000/689877 [01:59<00:57, 3885.26 examples/s]Running tokenizer on train dataset:  68%|██████▊   | 466000/689877 [02:00<00:57, 3880.92 examples/s]Running tokenizer on train dataset:  68%|██████▊   | 467000/689877 [02:00<00:57, 3887.71 examples/s]Running tokenizer on train dataset:  68%|██████▊   | 468000/689877 [02:00<00:56, 3895.53 examples/s]Running tokenizer on train dataset:  68%|██████▊   | 469000/689877 [02:00<00:56, 3880.49 examples/s]Running tokenizer on train dataset:  68%|██████▊   | 470000/689877 [02:01<00:56, 3894.73 examples/s]Running tokenizer on train dataset:  68%|██████▊   | 471000/689877 [02:01<00:56, 3899.17 examples/s]Running tokenizer on train dataset:  68%|██████▊   | 472000/689877 [02:01<00:55, 3892.89 examples/s]Running tokenizer on train dataset:  69%|██████▊   | 473000/689877 [02:01<00:55, 3877.25 examples/s]Running tokenizer on train dataset:  69%|██████▊   | 474000/689877 [02:02<00:55, 3898.49 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 475000/689877 [02:02<00:54, 3910.99 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 476000/689877 [02:02<00:55, 3885.84 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 477000/689877 [02:02<00:55, 3868.70 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 478000/689877 [02:03<00:56, 3769.70 examples/s]Running tokenizer on train dataset:  69%|██████▉   | 479000/689877 [02:03<00:55, 3821.63 examples/s]Running tokenizer on train dataset:  70%|██████▉   | 480000/689877 [02:03<00:54, 3825.41 examples/s]Running tokenizer on train dataset:  70%|██████▉   | 481000/689877 [02:03<00:54, 3862.69 examples/s]Running tokenizer on train dataset:  70%|██████▉   | 482000/689877 [02:04<00:53, 3879.71 examples/s]Running tokenizer on train dataset:  70%|███████   | 483000/689877 [02:04<00:53, 3879.62 examples/s]Running tokenizer on train dataset:  70%|███████   | 484000/689877 [02:04<00:53, 3871.15 examples/s]Running tokenizer on train dataset:  70%|███████   | 485000/689877 [02:04<00:52, 3891.59 examples/s]Running tokenizer on train dataset:  70%|███████   | 486000/689877 [02:05<00:52, 3911.24 examples/s]Running tokenizer on train dataset:  71%|███████   | 487000/689877 [02:05<00:52, 3887.63 examples/s]Running tokenizer on train dataset:  71%|███████   | 488000/689877 [02:05<00:51, 3893.17 examples/s]Running tokenizer on train dataset:  71%|███████   | 489000/689877 [02:05<00:51, 3896.82 examples/s]Running tokenizer on train dataset:  71%|███████   | 490000/689877 [02:06<00:51, 3907.99 examples/s]Running tokenizer on train dataset:  71%|███████   | 491000/689877 [02:06<00:51, 3892.00 examples/s]Running tokenizer on train dataset:  71%|███████▏  | 492000/689877 [02:06<00:50, 3908.11 examples/s]Running tokenizer on train dataset:  71%|███████▏  | 493000/689877 [02:06<00:50, 3913.59 examples/s]Running tokenizer on train dataset:  72%|███████▏  | 494000/689877 [02:07<00:50, 3906.62 examples/s]Running tokenizer on train dataset:  72%|███████▏  | 495000/689877 [02:07<00:50, 3891.10 examples/s]Running tokenizer on train dataset:  72%|███████▏  | 496000/689877 [02:07<00:49, 3905.74 examples/s]Running tokenizer on train dataset:  72%|███████▏  | 497000/689877 [02:07<00:49, 3916.92 examples/s]Running tokenizer on train dataset:  72%|███████▏  | 498000/689877 [02:08<00:49, 3897.50 examples/s]Running tokenizer on train dataset:  72%|███████▏  | 499000/689877 [02:08<00:48, 3898.13 examples/s]Running tokenizer on train dataset:  72%|███████▏  | 500000/689877 [02:08<00:48, 3906.85 examples/s]Running tokenizer on train dataset:  73%|███████▎  | 501000/689877 [02:09<00:48, 3911.41 examples/s]Running tokenizer on train dataset:  73%|███████▎  | 502000/689877 [02:09<00:48, 3890.81 examples/s]Running tokenizer on train dataset:  73%|███████▎  | 503000/689877 [02:09<00:48, 3893.22 examples/s]Running tokenizer on train dataset:  73%|███████▎  | 504000/689877 [02:09<00:47, 3904.75 examples/s]Running tokenizer on train dataset:  73%|███████▎  | 505000/689877 [02:10<00:47, 3901.68 examples/s]Running tokenizer on train dataset:  73%|███████▎  | 506000/689877 [02:10<00:47, 3887.61 examples/s]Running tokenizer on train dataset:  73%|███████▎  | 507000/689877 [02:10<00:46, 3895.16 examples/s]Running tokenizer on train dataset:  74%|███████▎  | 508000/689877 [02:10<00:46, 3909.85 examples/s]Running tokenizer on train dataset:  74%|███████▍  | 509000/689877 [02:11<00:46, 3895.69 examples/s]Running tokenizer on train dataset:  74%|███████▍  | 510000/689877 [02:11<00:46, 3898.35 examples/s]Running tokenizer on train dataset:  74%|███████▍  | 511000/689877 [02:11<00:45, 3903.34 examples/s]Running tokenizer on train dataset:  74%|███████▍  | 512000/689877 [02:11<00:45, 3911.10 examples/s]Running tokenizer on train dataset:  74%|███████▍  | 513000/689877 [02:12<00:45, 3891.48 examples/s]Running tokenizer on train dataset:  75%|███████▍  | 514000/689877 [02:12<00:45, 3902.54 examples/s]Running tokenizer on train dataset:  75%|███████▍  | 515000/689877 [02:12<00:44, 3913.70 examples/s]Running tokenizer on train dataset:  75%|███████▍  | 516000/689877 [02:12<00:44, 3910.75 examples/s]Running tokenizer on train dataset:  75%|███████▍  | 517000/689877 [02:13<00:44, 3888.55 examples/s]Running tokenizer on train dataset:  75%|███████▌  | 518000/689877 [02:13<00:44, 3893.77 examples/s]Running tokenizer on train dataset:  75%|███████▌  | 519000/689877 [02:13<00:43, 3907.17 examples/s]Running tokenizer on train dataset:  75%|███████▌  | 520000/689877 [02:13<00:43, 3890.74 examples/s]Running tokenizer on train dataset:  76%|███████▌  | 521000/689877 [02:14<00:43, 3892.90 examples/s]Running tokenizer on train dataset:  76%|███████▌  | 522000/689877 [02:14<00:42, 3904.92 examples/s]Running tokenizer on train dataset:  76%|███████▌  | 523000/689877 [02:14<00:42, 3910.51 examples/s]Running tokenizer on train dataset:  76%|███████▌  | 524000/689877 [02:14<00:42, 3882.78 examples/s]Running tokenizer on train dataset:  76%|███████▌  | 525000/689877 [02:15<00:42, 3901.71 examples/s]Running tokenizer on train dataset:  76%|███████▌  | 526000/689877 [02:15<00:41, 3916.65 examples/s]Running tokenizer on train dataset:  76%|███████▋  | 527000/689877 [02:15<00:41, 3905.44 examples/s]Running tokenizer on train dataset:  77%|███████▋  | 528000/689877 [02:15<00:41, 3894.59 examples/s]Running tokenizer on train dataset:  77%|███████▋  | 529000/689877 [02:16<00:41, 3901.03 examples/s]Running tokenizer on train dataset:  77%|███████▋  | 530000/689877 [02:16<00:40, 3909.31 examples/s]Running tokenizer on train dataset:  77%|███████▋  | 531000/689877 [02:16<00:40, 3898.98 examples/s]Running tokenizer on train dataset:  77%|███████▋  | 532000/689877 [02:16<00:40, 3897.99 examples/s]Running tokenizer on train dataset:  77%|███████▋  | 533000/689877 [02:17<00:40, 3904.58 examples/s]Running tokenizer on train dataset:  77%|███████▋  | 534000/689877 [02:17<00:39, 3910.38 examples/s]Running tokenizer on train dataset:  78%|███████▊  | 535000/689877 [02:17<00:39, 3889.44 examples/s]Running tokenizer on train dataset:  78%|███████▊  | 536000/689877 [02:18<00:40, 3762.11 examples/s]Running tokenizer on train dataset:  78%|███████▊  | 537000/689877 [02:18<00:40, 3809.51 examples/s]Running tokenizer on train dataset:  78%|███████▊  | 538000/689877 [02:18<00:39, 3822.85 examples/s]Running tokenizer on train dataset:  78%|███████▊  | 539000/689877 [02:18<00:39, 3834.82 examples/s]Running tokenizer on train dataset:  78%|███████▊  | 540000/689877 [02:19<00:38, 3859.21 examples/s]Running tokenizer on train dataset:  78%|███████▊  | 541000/689877 [02:19<00:38, 3877.56 examples/s]Running tokenizer on train dataset:  79%|███████▊  | 542000/689877 [02:19<00:38, 3875.49 examples/s]Running tokenizer on train dataset:  79%|███████▊  | 543000/689877 [02:19<00:37, 3885.54 examples/s]Running tokenizer on train dataset:  79%|███████▉  | 544000/689877 [02:20<00:37, 3895.89 examples/s]Running tokenizer on train dataset:  79%|███████▉  | 545000/689877 [02:20<00:37, 3898.51 examples/s]Running tokenizer on train dataset:  79%|███████▉  | 546000/689877 [02:20<00:37, 3876.97 examples/s]Running tokenizer on train dataset:  79%|███████▉  | 547000/689877 [02:20<00:36, 3896.22 examples/s]Running tokenizer on train dataset:  79%|███████▉  | 548000/689877 [02:21<00:36, 3916.30 examples/s]Running tokenizer on train dataset:  80%|███████▉  | 549000/689877 [02:21<00:38, 3626.74 examples/s]Running tokenizer on train dataset:  80%|███████▉  | 550000/689877 [02:21<00:37, 3688.05 examples/s]Running tokenizer on train dataset:  80%|███████▉  | 551000/689877 [02:21<00:37, 3745.02 examples/s]Running tokenizer on train dataset:  80%|████████  | 552000/689877 [02:22<00:36, 3794.60 examples/s]Running tokenizer on train dataset:  80%|████████  | 553000/689877 [02:22<00:35, 3805.92 examples/s]Running tokenizer on train dataset:  80%|████████  | 554000/689877 [02:22<00:35, 3834.42 examples/s]Running tokenizer on train dataset:  80%|████████  | 555000/689877 [02:22<00:35, 3847.32 examples/s]Running tokenizer on train dataset:  81%|████████  | 556000/689877 [02:23<00:34, 3856.67 examples/s]Running tokenizer on train dataset:  81%|████████  | 557000/689877 [02:23<00:34, 3851.98 examples/s]Running tokenizer on train dataset:  81%|████████  | 558000/689877 [02:23<00:33, 3882.41 examples/s]Running tokenizer on train dataset:  81%|████████  | 559000/689877 [02:23<00:33, 3899.54 examples/s]Running tokenizer on train dataset:  81%|████████  | 560000/689877 [02:24<00:33, 3878.44 examples/s]Running tokenizer on train dataset:  81%|████████▏ | 561000/689877 [02:24<00:33, 3878.19 examples/s]Running tokenizer on train dataset:  81%|████████▏ | 562000/689877 [02:24<00:32, 3886.26 examples/s]Running tokenizer on train dataset:  82%|████████▏ | 563000/689877 [02:25<00:32, 3899.28 examples/s]Running tokenizer on train dataset:  82%|████████▏ | 564000/689877 [02:25<00:32, 3888.71 examples/s]Running tokenizer on train dataset:  82%|████████▏ | 565000/689877 [02:25<00:32, 3902.00 examples/s]Running tokenizer on train dataset:  82%|████████▏ | 566000/689877 [02:25<00:31, 3909.27 examples/s]Running tokenizer on train dataset:  82%|████████▏ | 567000/689877 [02:26<00:31, 3904.29 examples/s]Running tokenizer on train dataset:  82%|████████▏ | 568000/689877 [02:26<00:31, 3887.94 examples/s]Running tokenizer on train dataset:  82%|████████▏ | 569000/689877 [02:26<00:30, 3906.93 examples/s]Running tokenizer on train dataset:  83%|████████▎ | 570000/689877 [02:26<00:30, 3916.76 examples/s]Running tokenizer on train dataset:  83%|████████▎ | 571000/689877 [02:27<00:30, 3895.27 examples/s]Running tokenizer on train dataset:  83%|████████▎ | 572000/689877 [02:27<00:30, 3896.29 examples/s]Running tokenizer on train dataset:  83%|████████▎ | 573000/689877 [02:27<00:29, 3904.40 examples/s]Running tokenizer on train dataset:  83%|████████▎ | 574000/689877 [02:27<00:29, 3914.36 examples/s]Running tokenizer on train dataset:  83%|████████▎ | 575000/689877 [02:28<00:29, 3890.49 examples/s]Running tokenizer on train dataset:  83%|████████▎ | 576000/689877 [02:28<00:29, 3907.85 examples/s]Running tokenizer on train dataset:  84%|████████▎ | 577000/689877 [02:28<00:28, 3915.25 examples/s]Running tokenizer on train dataset:  84%|████████▍ | 578000/689877 [02:28<00:28, 3908.18 examples/s]Running tokenizer on train dataset:  84%|████████▍ | 579000/689877 [02:29<00:28, 3886.94 examples/s]Running tokenizer on train dataset:  84%|████████▍ | 580000/689877 [02:29<00:28, 3900.67 examples/s]Running tokenizer on train dataset:  84%|████████▍ | 581000/689877 [02:29<00:27, 3908.84 examples/s]Running tokenizer on train dataset:  84%|████████▍ | 582000/689877 [02:29<00:27, 3889.49 examples/s]Running tokenizer on train dataset:  85%|████████▍ | 583000/689877 [02:30<00:27, 3889.81 examples/s]Running tokenizer on train dataset:  85%|████████▍ | 584000/689877 [02:30<00:27, 3901.14 examples/s]Running tokenizer on train dataset:  85%|████████▍ | 585000/689877 [02:30<00:26, 3912.27 examples/s]Running tokenizer on train dataset:  85%|████████▍ | 586000/689877 [02:30<00:26, 3888.48 examples/s]Running tokenizer on train dataset:  85%|████████▌ | 587000/689877 [02:31<00:26, 3902.43 examples/s]Running tokenizer on train dataset:  85%|████████▌ | 588000/689877 [02:31<00:26, 3909.60 examples/s]Running tokenizer on train dataset:  85%|████████▌ | 589000/689877 [02:31<00:25, 3903.13 examples/s]Running tokenizer on train dataset:  86%|████████▌ | 590000/689877 [02:31<00:25, 3891.93 examples/s]Running tokenizer on train dataset:  86%|████████▌ | 591000/689877 [02:32<00:25, 3896.13 examples/s]Running tokenizer on train dataset:  86%|████████▌ | 592000/689877 [02:32<00:25, 3909.08 examples/s]Running tokenizer on train dataset:  86%|████████▌ | 593000/689877 [02:32<00:24, 3892.32 examples/s]Running tokenizer on train dataset:  86%|████████▌ | 594000/689877 [02:32<00:25, 3754.25 examples/s]Running tokenizer on train dataset:  86%|████████▌ | 595000/689877 [02:33<00:24, 3802.07 examples/s]Running tokenizer on train dataset:  86%|████████▋ | 596000/689877 [02:33<00:24, 3825.50 examples/s]Running tokenizer on train dataset:  87%|████████▋ | 597000/689877 [02:33<00:24, 3828.28 examples/s]Running tokenizer on train dataset:  87%|████████▋ | 598000/689877 [02:34<00:23, 3858.60 examples/s]Running tokenizer on train dataset:  87%|████████▋ | 599000/689877 [02:34<00:23, 3882.78 examples/s]Running tokenizer on train dataset:  87%|████████▋ | 600000/689877 [02:34<00:23, 3874.22 examples/s]Running tokenizer on train dataset:  87%|████████▋ | 601000/689877 [02:34<00:22, 3866.96 examples/s]Running tokenizer on train dataset:  87%|████████▋ | 602000/689877 [02:35<00:22, 3878.71 examples/s]Running tokenizer on train dataset:  87%|████████▋ | 603000/689877 [02:35<00:22, 3896.30 examples/s]Running tokenizer on train dataset:  88%|████████▊ | 604000/689877 [02:35<00:22, 3882.71 examples/s]Running tokenizer on train dataset:  88%|████████▊ | 605000/689877 [02:35<00:21, 3883.79 examples/s]Running tokenizer on train dataset:  88%|████████▊ | 606000/689877 [02:36<00:21, 3885.41 examples/s]Running tokenizer on train dataset:  88%|████████▊ | 607000/689877 [02:36<00:21, 3899.81 examples/s]Running tokenizer on train dataset:  88%|████████▊ | 608000/689877 [02:36<00:21, 3879.17 examples/s]Running tokenizer on train dataset:  88%|████████▊ | 609000/689877 [02:36<00:20, 3895.77 examples/s]Running tokenizer on train dataset:  88%|████████▊ | 610000/689877 [02:37<00:20, 3911.12 examples/s]Running tokenizer on train dataset:  89%|████████▊ | 611000/689877 [02:37<00:20, 3897.66 examples/s]Running tokenizer on train dataset:  89%|████████▊ | 612000/689877 [02:37<00:20, 3880.67 examples/s]Running tokenizer on train dataset:  89%|████████▉ | 613000/689877 [02:37<00:19, 3893.56 examples/s]Running tokenizer on train dataset:  89%|████████▉ | 614000/689877 [02:38<00:19, 3905.86 examples/s]Running tokenizer on train dataset:  89%|████████▉ | 615000/689877 [02:38<00:19, 3891.80 examples/s]Running tokenizer on train dataset:  89%|████████▉ | 616000/689877 [02:38<00:18, 3891.66 examples/s]Running tokenizer on train dataset:  89%|████████▉ | 617000/689877 [02:38<00:18, 3899.55 examples/s]Running tokenizer on train dataset:  90%|████████▉ | 618000/689877 [02:39<00:18, 3904.34 examples/s]Running tokenizer on train dataset:  90%|████████▉ | 619000/689877 [02:39<00:18, 3877.02 examples/s]Running tokenizer on train dataset:  90%|████████▉ | 620000/689877 [02:39<00:17, 3896.73 examples/s]Running tokenizer on train dataset:  90%|█████████ | 621000/689877 [02:39<00:17, 3905.99 examples/s]Running tokenizer on train dataset:  90%|█████████ | 622000/689877 [02:40<00:17, 3890.96 examples/s]Running tokenizer on train dataset:  90%|█████████ | 623000/689877 [02:40<00:17, 3880.65 examples/s]Running tokenizer on train dataset:  90%|█████████ | 624000/689877 [02:40<00:16, 3888.03 examples/s]Running tokenizer on train dataset:  91%|█████████ | 625000/689877 [02:40<00:16, 3901.04 examples/s]Running tokenizer on train dataset:  91%|█████████ | 626000/689877 [02:41<00:16, 3889.11 examples/s]Running tokenizer on train dataset:  91%|█████████ | 627000/689877 [02:41<00:16, 3890.84 examples/s]Running tokenizer on train dataset:  91%|█████████ | 628000/689877 [02:41<00:15, 3898.53 examples/s]Running tokenizer on train dataset:  91%|█████████ | 629000/689877 [02:41<00:15, 3899.95 examples/s]Running tokenizer on train dataset:  91%|█████████▏| 630000/689877 [02:42<00:15, 3879.68 examples/s]Running tokenizer on train dataset:  91%|█████████▏| 631000/689877 [02:42<00:15, 3895.05 examples/s]Running tokenizer on train dataset:  92%|█████████▏| 632000/689877 [02:42<00:14, 3916.02 examples/s]Running tokenizer on train dataset:  92%|█████████▏| 633000/689877 [02:43<00:14, 3892.72 examples/s]Running tokenizer on train dataset:  92%|█████████▏| 634000/689877 [02:43<00:14, 3882.76 examples/s]Running tokenizer on train dataset:  92%|█████████▏| 635000/689877 [02:43<00:14, 3896.05 examples/s]Running tokenizer on train dataset:  92%|█████████▏| 636000/689877 [02:43<00:13, 3908.18 examples/s]Running tokenizer on train dataset:  92%|█████████▏| 637000/689877 [02:44<00:13, 3890.90 examples/s]Running tokenizer on train dataset:  92%|█████████▏| 638000/689877 [02:44<00:13, 3903.29 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 639000/689877 [02:44<00:13, 3901.30 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 640000/689877 [02:44<00:12, 3903.08 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 641000/689877 [02:45<00:12, 3880.39 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 642000/689877 [02:45<00:12, 3898.68 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 643000/689877 [02:45<00:12, 3894.08 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 644000/689877 [02:45<00:11, 3877.97 examples/s]Running tokenizer on train dataset:  93%|█████████▎| 645000/689877 [02:46<00:11, 3873.68 examples/s]Running tokenizer on train dataset:  94%|█████████▎| 646000/689877 [02:46<00:11, 3875.77 examples/s]Running tokenizer on train dataset:  94%|█████████▍| 647000/689877 [02:46<00:11, 3896.73 examples/s]Running tokenizer on train dataset:  94%|█████████▍| 648000/689877 [02:46<00:10, 3880.45 examples/s]Running tokenizer on train dataset:  94%|█████████▍| 649000/689877 [02:47<00:10, 3894.40 examples/s]Running tokenizer on train dataset:  94%|█████████▍| 650000/689877 [02:47<00:10, 3896.62 examples/s]Running tokenizer on train dataset:  94%|█████████▍| 651000/689877 [02:47<00:09, 3892.05 examples/s]Running tokenizer on train dataset:  95%|█████████▍| 652000/689877 [02:47<00:09, 3793.77 examples/s]Running tokenizer on train dataset:  95%|█████████▍| 653000/689877 [02:48<00:09, 3774.84 examples/s]Running tokenizer on train dataset:  95%|█████████▍| 654000/689877 [02:48<00:09, 3819.28 examples/s]Running tokenizer on train dataset:  95%|█████████▍| 655000/689877 [02:48<00:09, 3823.92 examples/s]Running tokenizer on train dataset:  95%|█████████▌| 656000/689877 [02:48<00:08, 3841.01 examples/s]Running tokenizer on train dataset:  95%|█████████▌| 657000/689877 [02:49<00:08, 3861.01 examples/s]Running tokenizer on train dataset:  95%|█████████▌| 658000/689877 [02:49<00:08, 3870.35 examples/s]Running tokenizer on train dataset:  96%|█████████▌| 659000/689877 [02:49<00:07, 3862.83 examples/s]Running tokenizer on train dataset:  96%|█████████▌| 660000/689877 [02:49<00:07, 3878.92 examples/s]Running tokenizer on train dataset:  96%|█████████▌| 661000/689877 [02:50<00:07, 3890.23 examples/s]Running tokenizer on train dataset:  96%|█████████▌| 662000/689877 [02:50<00:07, 3887.09 examples/s]Running tokenizer on train dataset:  96%|█████████▌| 663000/689877 [02:50<00:06, 3870.80 examples/s]Running tokenizer on train dataset:  96%|█████████▌| 664000/689877 [02:51<00:06, 3882.85 examples/s]Running tokenizer on train dataset:  96%|█████████▋| 665000/689877 [02:51<00:06, 3898.63 examples/s]Running tokenizer on train dataset:  97%|█████████▋| 666000/689877 [02:51<00:06, 3878.45 examples/s]Running tokenizer on train dataset:  97%|█████████▋| 667000/689877 [02:51<00:05, 3881.63 examples/s]Running tokenizer on train dataset:  97%|█████████▋| 668000/689877 [02:52<00:06, 3444.21 examples/s]Running tokenizer on train dataset:  97%|█████████▋| 669000/689877 [02:52<00:05, 3568.99 examples/s]Running tokenizer on train dataset:  97%|█████████▋| 670000/689877 [02:52<00:05, 3640.05 examples/s]Running tokenizer on train dataset:  97%|█████████▋| 671000/689877 [02:52<00:05, 3719.00 examples/s]Running tokenizer on train dataset:  97%|█████████▋| 672000/689877 [02:53<00:04, 3773.38 examples/s]Running tokenizer on train dataset:  98%|█████████▊| 673000/689877 [02:53<00:04, 3804.95 examples/s]Running tokenizer on train dataset:  98%|█████████▊| 674000/689877 [02:53<00:04, 3823.24 examples/s]Running tokenizer on train dataset:  98%|█████████▊| 675000/689877 [02:53<00:03, 3851.22 examples/s]Running tokenizer on train dataset:  98%|█████████▊| 676000/689877 [02:54<00:03, 3878.51 examples/s]Running tokenizer on train dataset:  98%|█████████▊| 677000/689877 [02:54<00:03, 3866.99 examples/s]Running tokenizer on train dataset:  98%|█████████▊| 678000/689877 [02:54<00:03, 3874.31 examples/s]Running tokenizer on train dataset:  98%|█████████▊| 679000/689877 [02:54<00:02, 3880.88 examples/s]Running tokenizer on train dataset:  99%|█████████▊| 680000/689877 [02:55<00:02, 3889.84 examples/s]Running tokenizer on train dataset:  99%|█████████▊| 681000/689877 [02:55<00:02, 3875.89 examples/s]Running tokenizer on train dataset:  99%|█████████▉| 682000/689877 [02:55<00:02, 3893.34 examples/s]Running tokenizer on train dataset:  99%|█████████▉| 683000/689877 [02:56<00:01, 3907.60 examples/s]Running tokenizer on train dataset:  99%|█████████▉| 684000/689877 [02:56<00:01, 3896.56 examples/s]Running tokenizer on train dataset:  99%|█████████▉| 685000/689877 [02:56<00:01, 3881.31 examples/s]Running tokenizer on train dataset:  99%|█████████▉| 686000/689877 [02:56<00:00, 3894.06 examples/s]Running tokenizer on train dataset: 100%|█████████▉| 687000/689877 [02:57<00:00, 3907.89 examples/s]Running tokenizer on train dataset: 100%|█████████▉| 688000/689877 [02:57<00:00, 3888.84 examples/s]Running tokenizer on train dataset: 100%|█████████▉| 689000/689877 [02:57<00:00, 3881.23 examples/s]Running tokenizer on train dataset: 100%|██████████| 689877/689877 [02:57<00:00, 3890.11 examples/s]Running tokenizer on train dataset: 100%|██████████| 689877/689877 [02:59<00:00, 3837.48 examples/s]
[INFO|configuration_utils.py:716] 2023-10-15 02:17:08,144 >> loading configuration file config.json from cache at /home/u131168/.cache/huggingface/hub/models--google--flan-t5-xl/snapshots/8772db7a7a11f7b08e6be7d7088f7a7fd4813bc5/config.json
[INFO|configuration_utils.py:776] 2023-10-15 02:17:08,157 >> Model config T5Config {
  "_name_or_path": "google/flan-t5-xl",
  "architectures": [
    "T5ForConditionalGeneration"
  ],
  "classifier_dropout": 0.0,
  "d_ff": 5120,
  "d_kv": 64,
  "d_model": 2048,
  "decoder_start_token_id": 0,
  "dense_act_fn": "gelu_new",
  "dropout_rate": 0.1,
  "eos_token_id": 1,
  "feed_forward_proj": "gated-gelu",
  "initializer_factor": 1.0,
  "is_encoder_decoder": true,
  "is_gated_act": true,
  "layer_norm_epsilon": 1e-06,
  "model_type": "t5",
  "n_positions": 512,
  "num_decoder_layers": 24,
  "num_heads": 32,
  "num_layers": 24,
  "output_past": true,
  "pad_token_id": 0,
  "relative_attention_max_distance": 128,
  "relative_attention_num_buckets": 32,
  "task_specific_params": {
    "summarization": {
      "early_stopping": true,
      "length_penalty": 2.0,
      "max_length": 200,
      "min_length": 30,
      "no_repeat_ngram_size": 3,
      "num_beams": 4,
      "prefix": "summarize: "
    },
    "translation_en_to_de": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to German: "
    },
    "translation_en_to_fr": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to French: "
    },
    "translation_en_to_ro": {
      "early_stopping": true,
      "max_length": 300,
      "num_beams": 4,
      "prefix": "translate English to Romanian: "
    }
  },
  "tie_word_embeddings": false,
  "torch_dtype": "float32",
  "transformers_version": "4.35.0.dev0",
  "use_cache": true,
  "vocab_size": 32128
}

[INFO|modeling_utils.py:2995] 2023-10-15 02:17:08,237 >> loading weights file pytorch_model.bin from cache at /home/u131168/.cache/huggingface/hub/models--google--flan-t5-xl/snapshots/8772db7a7a11f7b08e6be7d7088f7a7fd4813bc5/pytorch_model.bin.index.json
[INFO|configuration_utils.py:789] 2023-10-15 02:17:08,244 >> Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0
}

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.71s/it]
[INFO|modeling_utils.py:3779] 2023-10-15 02:17:25,841 >> All model checkpoint weights were used when initializing T5ForConditionalGeneration.

[INFO|modeling_utils.py:3787] 2023-10-15 02:17:25,842 >> All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at google/flan-t5-xl.
If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.
[INFO|configuration_utils.py:749] 2023-10-15 02:17:25,936 >> loading configuration file generation_config.json from cache at /home/u131168/.cache/huggingface/hub/models--google--flan-t5-xl/snapshots/8772db7a7a11f7b08e6be7d7088f7a7fd4813bc5/generation_config.json
[INFO|configuration_utils.py:789] 2023-10-15 02:17:25,937 >> Generate config GenerationConfig {
  "decoder_start_token_id": 0,
  "eos_token_id": 1,
  "pad_token_id": 0
}

[INFO|modeling_utils.py:1619] 2023-10-15 02:17:25,943 >> You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32105. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc
[INFO|trainer.py:584] 2023-10-15 02:17:31,115 >> Using cpu_amp half precision backend
[INFO|trainer.py:2008] 2023-10-15 02:17:31,120 >> Loading model from /home/u131168/mh_shell/ft_models/flan-t5-xl_mt5_v4/checkpoint-132900.
[INFO|trainer.py:1669] 2023-10-15 02:17:31,313 >> ***** Running training *****
[INFO|trainer.py:1670] 2023-10-15 02:17:31,313 >>   Num examples = 689,877
[INFO|trainer.py:1671] 2023-10-15 02:17:31,313 >>   Num Epochs = 1
[INFO|trainer.py:1672] 2023-10-15 02:17:31,313 >>   Instantaneous batch size per device = 2
[INFO|trainer.py:1675] 2023-10-15 02:17:31,313 >>   Total train batch size (w. parallel, distributed & accumulation) = 2
[INFO|trainer.py:1676] 2023-10-15 02:17:31,313 >>   Gradient Accumulation steps = 1
[INFO|trainer.py:1677] 2023-10-15 02:17:31,313 >>   Total optimization steps = 344,939
[INFO|trainer.py:1678] 2023-10-15 02:17:31,316 >>   Number of trainable parameters = 4,718,592
[INFO|trainer.py:1698] 2023-10-15 02:17:31,329 >>   Continuing training from checkpoint, will skip to saved global_step
[INFO|trainer.py:1699] 2023-10-15 02:17:31,329 >>   Continuing training from epoch 0
[INFO|trainer.py:1700] 2023-10-15 02:17:31,329 >>   Continuing training from global step 132900
[INFO|trainer.py:1702] 2023-10-15 02:17:31,329 >>   Will skip the first 0 epochs then the first 132900 batches in the first epoch.
trainable params: 4,718,592 || all params: 2,854,381,568 || trainable%: 0.1653104845161332
  0%|          | 0/344939 [00:00<?, ?it/s][WARNING|logging.py:316] 2023-10-15 02:17:31,442 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
 39%|███▊      | 132901/344939 [00:01<00:02, 89540.18it/s] 39%|███▊      | 132907/344939 [00:19<00:02, 89540.18it/s] 39%|███▊      | 132908/344939 [00:22<00:49, 4242.52it/s]  39%|███▊      | 132909/344939 [00:24<00:57, 3709.97it/s]                                                          39%|███▊      | 132910/344939 [00:26<00:57, 3709.97it/s] 39%|███▊      | 132914/344939 [00:39<00:57, 3709.97it/s] 39%|███▊      | 132915/344939 [00:40<02:12, 1602.15it/s] 39%|███▊      | 132916/344939 [00:42<02:21, 1500.04it/s]                                                          39%|███▊      | 132920/344939 [00:48<02:21, 1500.04it/s] 39%|███▊      | 132927/344939 [00:59<02:21, 1500.04it/s] 39%|███▊      | 132928/344939 [00:59<05:07, 690.45it/s]  39%|███▊      | 132929/344939 [01:01<05:32, 637.86it/s]                                                         39%|███▊      | 132930/344939 [01:02<05:32, 637.86it/s] 39%|███▊      | 132938/344939 [01:19<05:32, 637.86it/s] 39%|███▊      | 132939/344939 [01:28<14:12, 248.71it/s] 39%|███▊      | 132940/344939 [01:29<14:52, 237.48it/s]                                                         39%|███▊      | 132940/344939 [01:29<14:52, 237.48it/s]                                                         39%|███▊      | 132950/344939 [01:47<14:52, 237.48it/s] 39%|███▊      | 132950/344939 [01:49<14:52, 237.48it/s] 39%|███▊      | 132951/344939 [01:49<27:48, 127.04it/s] 39%|███▊      | 132952/344939 [01:51<29:14, 120.83it/s]                                                         39%|███▊      | 132960/344939 [02:03<29:14, 120.83it/s] 39%|███▊      | 132963/344939 [02:09<29:14, 120.83it/s] 39%|███▊      | 132964/344939 [02:09<53:28, 66.06it/s]  39%|███▊      | 132965/344939 [02:11<56:48, 62.20it/s]                                                        39%|███▊      | 132970/344939 [02:19<56:48, 62.20it/s] 39%|███▊      | 132975/344939 [02:29<56:47, 62.20it/s] 39%|███▊      | 132976/344939 [02:29<1:46:36, 33.14it/s] 39%|███▊      | 132977/344939 [02:32<1:56:13, 30.40it/s]                                                          39%|███▊      | 132980/344939 [02:41<1:56:13, 30.40it/s] 39%|███▊      | 132983/344939 [02:49<1:56:13, 30.40it/s] 39%|███▊      | 132984/344939 [02:49<3:26:25, 17.11it/s] 39%|███▊      | 132985/344939 [02:51<3:41:10, 15.97it/s]                                                          39%|███▊      | 132990/344939 [03:01<3:41:10, 15.97it/s] 39%|███▊      | 132994/344939 [03:09<3:41:09, 15.97it/s] 39%|███▊      | 132995/344939 [03:10<7:01:01,  8.39it/s] 39%|███▊      | 132996/344939 [03:12<7:25:33,  7.93it/s]                                                          39%|███▊      | 133000/344939 [03:19<7:25:33,  7.93it/s][INFO|trainer.py:2806] 2023-10-15 02:20:50,344 >> Saving model checkpoint to /home/u131168/mh_shell/ft_models/flan-t5-xl_mt5_v4/checkpoint-133000
[INFO|trainer.py:2893] 2023-10-15 02:20:50,770 >> Deleting older checkpoint [/home/u131168/mh_shell/ft_models/flan-t5-xl_mt5_v4/checkpoint-132800] due to args.save_total_limit
 39%|███▊      | 133004/344939 [03:29<7:25:32,  7.93it/s] 39%|███▊      | 133005/344939 [03:30<13:28:24,  4.37it/s] 39%|███▊      | 133006/344939 [03:32<14:01:08,  4.20it/s]                                                           39%|███▊      | 133010/344939 [03:39<14:01:07,  4.20it/s] 39%|███▊      | 133016/344939 [03:49<14:01:06,  4.20it/s] 39%|███▊      | 133017/344939 [03:51<24:07:40,  2.44it/s] 39%|███▊      | 133018/344939 [03:52<25:03:35,  2.35it/s]                                                           39%|███▊      | 133020/344939 [03:56<25:03:34,  2.35it/s] 39%|███▊      | 133026/344939 [04:09<25:03:31,  2.35it/s] 39%|███▊      | 133027/344939 [04:09<38:50:23,  1.52it/s] 39%|███▊      | 133028/344939 [04:11<40:16:39,  1.46it/s]                                                           39%|███▊      | 133030/344939 [04:14<40:16:37,  1.46it/s] 39%|███▊      | 133037/344939 [04:29<40:16:33,  1.46it/s] 39%|███▊      | 133038/344939 [04:30<58:24:09,  1.01it/s] 39%|███▊      | 133039/344939 [04:32<60:53:38,  1.03s/it]                                                           39%|███▊      | 133040/344939 [04:34<60:53:37,  1.03s/it] 39%|███▊      | 133048/344939 [04:49<60:53:29,  1.03s/it] 39%|███▊      | 133049/344939 [04:51<78:06:29,  1.33s/it] 39%|███▊      | 133050/344939 [04:53<79:57:25,  1.36s/it]                                                           39%|███▊      | 133050/344939 [04:53<79:57:25,  1.36s/it] 39%|███▊      | 133057/344939 [05:09<79:57:16,  1.36s/it] 39%|███▊      | 133058/344939 [05:09<95:00:41,  1.61s/it] 39%|███▊      | 133059/344939 [05:12<96:55:25,  1.65s/it]                                                           39%|███▊      | 133060/344939 [05:13<96:55:23,  1.65s/it] 39%|███▊      | 133067/344939 [05:29<96:55:11,  1.65s/it] 39%|███▊      | 133068/344939 [05:29<104:07:11,  1.77s/it] 39%|███▊      | 133069/344939 [05:30<102:48:56,  1.75s/it]                                                            39%|███▊      | 133070/344939 [05:34<102:48:54,  1.75s/it] 39%|███▊      | 133077/344939 [05:49<102:48:42,  1.75s/it] 39%|███▊      | 133078/344939 [05:50<113:58:30,  1.94s/it] 39%|███▊      | 133079/344939 [05:51<110:22:50,  1.88s/it]                                                            39%|███▊      | 133080/344939 [05:53<110:22:49,  1.88s/it] 39%|███▊      | 133086/344939 [06:07<118:49:16,  2.02s/it]