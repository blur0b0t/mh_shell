{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tokenizers import AddedToken\n",
    "from transformers import T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"data/datafinal.json\"\n",
    "ftraind_path=\"data/f_traind.csv\"\n",
    "fdata_path=\"data/f_data.csv\"\n",
    "\n",
    "\n",
    "submission_path=\"data/submission.csv\"\n",
    "\n",
    "# vars\n",
    "col_text='Text'\n",
    "col_cc='ContainsCode'\n",
    "col_cl='CodeList'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                                             11\n",
       "Text            The field of software development is incredibl...\n",
       "ContainsCode                                                 True\n",
       "CodeList        #include <iostream> using namespace std; int m...\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data=pd.read_json(data_path)\n",
    "ftrain_data=pd.read_csv(ftraind_path)\n",
    "f_data=pd.read_csv(ftraind_path)\n",
    "\n",
    "train_data=full_data[full_data[col_cc]!=\"\"]\n",
    "test_data=full_data[full_data[col_cc]==\"\"]\n",
    "# pprint(train_data.iloc[1,1])\n",
    "train_data\n",
    "full_data.iloc[10]\n",
    "# full_data.to_csv(\"/home/u131168/mh_shell/data/datafinal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_dir='mh_shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /opt/miniconda/lib/python3.10/site-packages (0.41.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/u131168/.local/lib/python3.10/site-packages (0.23.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/u131168/.local/lib/python3.10/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/u131168/.local/lib/python3.10/site-packages (from accelerate) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/u131168/.local/lib/python3.10/site-packages (from accelerate) (1.26.0)\n",
      "Requirement already satisfied: pyyaml in /home/u131168/.local/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda/lib/python3.10/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in /home/u131168/.local/lib/python3.10/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: filelock in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.4)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.2.10.91)\n",
      "Requirement already satisfied: networkx in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.101)\n",
      "Requirement already satisfied: sympy in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.91)\n",
      "Requirement already satisfied: jinja2 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (65.6.3)\n",
      "Requirement already satisfied: wheel in /opt/miniconda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/u131168/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.5)\n",
      "Requirement already satisfied: lit in /home/u131168/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/miniconda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/u131168/.local/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
      "Requirement already satisfied: requests in /opt/miniconda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/u131168/.local/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/u131168/.local/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: scipy in /opt/miniconda/lib/python3.10/site-packages (1.11.2)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /home/u131168/.local/lib/python3.10/site-packages (from scipy) (1.26.0)\n",
      "Requirement already satisfied: transformers in /opt/miniconda/lib/python3.10/site-packages (4.35.0.dev0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/u131168/.local/lib/python3.10/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/u131168/.local/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/miniconda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: filelock in /home/u131168/.local/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/u131168/.local/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/u131168/.local/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/u131168/.local/lib/python3.10/site-packages (from transformers) (0.14.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/u131168/.local/lib/python3.10/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: fsspec in /home/u131168/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/u131168/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: peft in /home/u131168/.local/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: transformers in /opt/miniconda/lib/python3.10/site-packages (from peft) (4.35.0.dev0)\n",
      "Requirement already satisfied: pyyaml in /home/u131168/.local/lib/python3.10/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: psutil in /home/u131168/.local/lib/python3.10/site-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda/lib/python3.10/site-packages (from peft) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda/lib/python3.10/site-packages (from peft) (23.0)\n",
      "Requirement already satisfied: safetensors in /home/u131168/.local/lib/python3.10/site-packages (from peft) (0.3.3)\n",
      "Requirement already satisfied: accelerate in /home/u131168/.local/lib/python3.10/site-packages (from peft) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/u131168/.local/lib/python3.10/site-packages (from peft) (1.26.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/u131168/.local/lib/python3.10/site-packages (from peft) (2.0.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.99)\n",
      "Requirement already satisfied: sympy in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (8.5.0.96)\n",
      "Requirement already satisfied: jinja2 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: filelock in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.12.4)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.10.3.66)\n",
      "Requirement already satisfied: networkx in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\n",
      "Requirement already satisfied: typing-extensions in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (4.8.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.101)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.2.10.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.0.0)\n",
      "Requirement already satisfied: wheel in /opt/miniconda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft) (65.6.3)\n",
      "Requirement already satisfied: lit in /home/u131168/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13.0->peft) (16.0.6)\n",
      "Requirement already satisfied: cmake in /home/u131168/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13.0->peft) (3.27.5)\n",
      "Requirement already satisfied: huggingface-hub in /home/u131168/.local/lib/python3.10/site-packages (from accelerate->peft) (0.16.4)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/u131168/.local/lib/python3.10/site-packages (from transformers->peft) (0.14.0)\n",
      "Requirement already satisfied: requests in /opt/miniconda/lib/python3.10/site-packages (from transformers->peft) (2.31.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/u131168/.local/lib/python3.10/site-packages (from transformers->peft) (2023.8.8)\n",
      "Requirement already satisfied: fsspec in /home/u131168/.local/lib/python3.10/site-packages (from huggingface-hub->accelerate->peft) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/u131168/.local/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers->peft) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers->peft) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers->peft) (1.26.15)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/u131168/.local/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install bitsandbytes\n",
    "# !pip install accelerate\n",
    "# !pip install scipy\n",
    "# !pip install transformers\n",
    "# !pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokenizer():\n",
    "    \n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "    stokens_v1=[\"`\",\"~\",\"!\",\"@\",\"#\",\"$\",\"%\",\"^\",\"&\",\"*\",\"(\",\")\",\"-\",\"_\",\"+\",\"=\",\"{\",\"}\",\"[\",\"]\",\"|\",\"\\\\\",\":\",\";\",\"\\\"\",\"'\",\"<\",\">\",\"?\",\"/\",\"\\n\",\"\\t\",\" \"]\n",
    "    stokens=stokens_v1\n",
    "    for st in stokens:\n",
    "        tokenizer.add_tokens(AddedToken(st, normalized=False),special_tokens=False)\n",
    "    return tokenizer\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf2a2bfb95947da9e2428aa86f26b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from peft import AutoPeftModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "# model_path=\"google/flan-t5-xl\"\n",
    "model_path=f\"/home/u131168/{mh_dir}/ft_models/flan-t5-xl_peft_finetuned_model/checkpoint-11700\"\n",
    "# model_path=f\"/home/u131168/{mh_dir}/ft_models/flan-t5-xl_mt5/checkpoint-34600\"\n",
    "\n",
    "# model_path=f\"/home/u131168/{mh_dir}/ft_models/flan-t5-xl_mt5_v1/7000\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "custom_model = AutoPeftModelForSeq2SeqLM.from_pretrained(model_path, )\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "\n",
    "# tokenizer=getTokenizer()\n",
    "# custom_model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# p_count=50\n",
    "psi,pei=58,68\n",
    "# psi,pei=250,258\n",
    "# prompts = ftrain_data.loc[psi:pei,['input','instruction']].values.tolist()\n",
    "prompts = f_data.loc[psi:pei,['input','instruction']].values.tolist()\n",
    "\n",
    "# instruction=\"extract code snippets from the paragraph, if it does not contain code snippets then say none\"\n",
    "\n",
    "t_prompts=[]\n",
    "for p in prompts:\n",
    "    context=str(p[0])\n",
    "    question=p[1]\n",
    "    t_prompts.append([context, question])\n",
    "    # t_prompts+=[f\"input: {context}\\n\\ninstruction: {question}\"]\n",
    "\n",
    "prompts=t_prompts\n",
    "# prompts = ftrain_data.loc[:p_count,['input','instruction']].values.tolist()\n",
    "# pprint(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "# stokens=[]\n",
    "# stokens=[\"{\", \"}\" ,\"\\n\",\"<\", \">\",\" \",'\\\\','/','^']\n",
    "# for st in stokens:\n",
    "    # tokenizer.add_tokens(AddedToken(st, normalized=False))\n",
    "\n",
    "\n",
    "# tokenizer.add_tokens(stokens,special_tokens=False)\n",
    "\n",
    "\n",
    "input_ids = tokenizer(prompts, return_tensors=\"pt\" ,padding=True,truncation=True, max_length=512).input_ids\n",
    "# sample up to 30 tokens\n",
    "torch.manual_seed(0)  # doctest: +IGNORE_RESULT\n",
    "outputs = custom_model.generate(input_ids=input_ids, do_sample=True, max_length=512)\n",
    "# pred_custom=tokenizer.batch_decode(outputs, skip_special_tokens=True,spaces_between_special_tokens = False)\n",
    "# pred_custom=tokenizer.batch_decode(outputs, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_custom=tokenizer.batch_decode(outputs, skip_special_tokens=True,spaces_between_special_tokens = False)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "# stokens=[\"`\",\"~\",\"!\",\"@\",\"#\",\"$\",\"%\",\"^\",\"&\",\"*\",\"(\",\")\",\"-\",\"_\",\"+\",\"=\",\"{\",\"}\",\"[\",\"]\",\"|\",\"\\\\\",\":\",\";\",\"\\\"\",\"'\",\"<\",\">\",\"?\",\"/\",\"\\n\",\" \"]\n",
    "# for st in stokens:\n",
    "#     tokenizer.add_tokens(AddedToken(st, normalized=False),special_tokens=False)\n",
    "\n",
    "# pred_custom=tokenizer.batch_decode(outputs, skip_special_tokens=True,spaces_between_special_tokens = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # !pip install transformers\n",
    "# # from transformers import AutoTokenizer\n",
    "# # from transformers import T5Tokenizer\n",
    "\n",
    "# # from tokenizers import AddedToken\n",
    "# text=\"int arr[5] = \\n\\{`~1,};:[ ]\\++++ - *&^%$#@!_+)'5>2,\"\n",
    "# # # text=\"int arr[5] = {1, 2, 3, 4, 5};', 'for(int i=0; i<5; i++) {cout << arr[i] << endl;}\"\n",
    "# # # text=\"function add(a, b) { \\n\\n<< return a + b; }\"\n",
    "\n",
    "# # # tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "# # # tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# # stokens=[]\n",
    "# # stokens=[\"{\", \"}\" ,\"\\n\",\"<\",'\\\\','/','^',\" \",\"`\",\"~\"]\n",
    "# stokens=[\"`\",\"~\",\"!\",\"@\",\"#\",\"$\",\"%\",\"^\",\"&\",\"*\",\"(\",\")\",\"-\",\"_\",\"+\",\"=\",\"{\",\"}\",\"[\",\"]\",\"|\",\"\\\\\",\":\",\";\",\"\\\"\",\"'\",\"<\",\">\",\"?\",\"/\",\"\\n\",\" \"]\n",
    "# for st in stokens:\n",
    "#     tokenizer.add_tokens(AddedToken(st, normalized=False),special_tokens=False)\n",
    "\n",
    "# # # tokenizer.add_tokens([\"{\",\"}\",\"<\",\"\\n\"])\n",
    "# input_ids = tokenizer(text, return_tensors=\"pt\" ,padding=True,truncation=True, max_length=512).input_ids\n",
    "# # # pred_custom=tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "# print([text])\n",
    "# print(tokenizer.batch_decode(input_ids,skip_special_tokens=True,spaces_between_special_tokens = False))\n",
    "# print(tokenizer.batch_decode(input_ids,skip_special_tokens=True,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>input</th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "      <th>pred_custom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>paragraph:  In software development, debugging...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>int arr[5] = {1, 2, 3, 4, 5};', 'for(int i=0; ...</td>\n",
       "      <td>int arr[5] = 1, 2, 3, 4, 5;', 'for(int i=0; i5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>paragraph:  Software developers are in high de...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>paragraph:  Developing software is a complex t...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>function add(a, b) { return a + b; }</td>\n",
       "      <td>function add(a, b)  return a + b;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>paragraph:  Software development is a field th...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>paragraph:  Software development is a field th...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63</td>\n",
       "      <td>paragraph:  When it comes to software developm...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>numbers = [5, 1, 9, 3, 7]; sorted_numbers = so...</td>\n",
       "      <td>numbers = [5, 1, 9, 3, 7]; sorted_numbers = so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>paragraph:  Software development is a multi-fa...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>#include &lt;iostream&gt;; int main() { std::cout &lt;&lt;...</td>\n",
       "      <td>#include iostream&gt;; int main()  std::cout  'He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>65</td>\n",
       "      <td>paragraph:  The world of software development ...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>66</td>\n",
       "      <td>paragraph:  Software development is an excitin...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>67</td>\n",
       "      <td>paragraph:  Software development is a fast-pac...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>function square(number) { return number * numb...</td>\n",
       "      <td>function square(number)  return number * number;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>68</td>\n",
       "      <td>paragraph:  In the realm of software developme...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                              input  \\\n",
       "0      58  paragraph:  In software development, debugging...   \n",
       "1      59  paragraph:  Software developers are in high de...   \n",
       "2      60  paragraph:  Developing software is a complex t...   \n",
       "3      61  paragraph:  Software development is a field th...   \n",
       "4      62  paragraph:  Software development is a field th...   \n",
       "5      63  paragraph:  When it comes to software developm...   \n",
       "6      64  paragraph:  Software development is a multi-fa...   \n",
       "7      65  paragraph:  The world of software development ...   \n",
       "8      66  paragraph:  Software development is an excitin...   \n",
       "9      67  paragraph:  Software development is a fast-pac...   \n",
       "10     68  paragraph:  In the realm of software developme...   \n",
       "\n",
       "                                          instruction  \\\n",
       "0   extract code snippets from the paragraph, if i...   \n",
       "1   extract code snippets from the paragraph, if i...   \n",
       "2   extract code snippets from the paragraph, if i...   \n",
       "3   extract code snippets from the paragraph, if i...   \n",
       "4   extract code snippets from the paragraph, if i...   \n",
       "5   extract code snippets from the paragraph, if i...   \n",
       "6   extract code snippets from the paragraph, if i...   \n",
       "7   extract code snippets from the paragraph, if i...   \n",
       "8   extract code snippets from the paragraph, if i...   \n",
       "9   extract code snippets from the paragraph, if i...   \n",
       "10  extract code snippets from the paragraph, if i...   \n",
       "\n",
       "                                               output  \\\n",
       "0   int arr[5] = {1, 2, 3, 4, 5};', 'for(int i=0; ...   \n",
       "1                                                none   \n",
       "2                function add(a, b) { return a + b; }   \n",
       "3                                                none   \n",
       "4                                                none   \n",
       "5   numbers = [5, 1, 9, 3, 7]; sorted_numbers = so...   \n",
       "6   #include <iostream>; int main() { std::cout <<...   \n",
       "7                                                none   \n",
       "8                                                none   \n",
       "9   function square(number) { return number * numb...   \n",
       "10                                               none   \n",
       "\n",
       "                                          pred_custom  \n",
       "0   int arr[5] = 1, 2, 3, 4, 5;', 'for(int i=0; i5...  \n",
       "1                                                none  \n",
       "2                  function add(a, b)  return a + b;   \n",
       "3                                                none  \n",
       "4                                                none  \n",
       "5   numbers = [5, 1, 9, 3, 7]; sorted_numbers = so...  \n",
       "6   #include iostream>; int main()  std::cout  'He...  \n",
       "7                                                none  \n",
       "8                                                none  \n",
       "9   function square(number)  return number * number;   \n",
       "10                                               none  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_custom_df=pd.DataFrame(pd.Series(pred_custom,name=\"pred_custom\"))\n",
    "# pred_ft5_df=pd.DataFrame(pd.Series(pred_ft5,name=\"pred_ft5\"))\n",
    "# temp_df=pd.concat([ftrain_data.iloc[psi:pei+1].reset_index(),pred_custom_df],axis=1)\n",
    "temp_df=pd.concat([f_data.iloc[psi:pei+1].reset_index(),pred_custom_df],axis=1)\n",
    "\n",
    "temp_df\n",
    "# pprint(temp_df.iloc[1,0])\n",
    "# print(temp_df.iloc[5,3])\n",
    "# print(temp_df.iloc[5,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"paragraph:  Software development is an exciting and rewarding career. It's a field where you can continually learn, solve challenging problems, and see the direct impact of your work. However, it's not without its challenges.\\n\\nOne of the main challenges in software development is staying updated with the constant changes in technology. The pace of change in the tech industry is rapid, and what's considered a best practice today might be outdated tomorrow.\\n\\nAnother challenge is the complexity of the problems you'll encounter. Software development is not just about writing code - it's about understanding complex systems, identifying problems, and finding the most effective and efficient solutions.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.iloc[8,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install tiktoken\n",
    "# # !pip install transformers\n",
    "# # model='Salesforce/codegen-350M-mono'\n",
    "# # model='Salesforce/codegen25-7b-instruct'\n",
    "# model=\"Phind/Phind-CodeLlama-34B-v1\"\n",
    "# import transformers\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model, trust_remote_code=True)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model)\n",
    "\n",
    "\n",
    "# # from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "# # model_path = \"Phind/Phind-CodeLlama-34B-v1\"\n",
    "# # model = LlamaForCausalLM.from_pretrained(model_path, device_map=\"auto\")\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pprint import pprint\n",
    "# # creating prompts\n",
    "# prompts=[]\n",
    "# for i in train_data[124:125].index:\n",
    "#     prompt='extract code from the following paragraph:\\n\\n\\n'+train_data.iloc[i,1].replace('\\n','')\n",
    "    \n",
    "#     # predict\n",
    "#     # text = \"def hello_world():\"\n",
    "#     # text = prompt\n",
    "#     # input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "#     # generated_ids = model.generate(input_ids, max_length=128)\n",
    "#     # res=tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "#     tokenizer.pad_token = tokenizer.eos_token\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=4096)\n",
    "\n",
    "#     # Generate\n",
    "#     generate_ids = model.generate(inputs.input_ids, max_new_tokens=256, do_sample=True, top_p=0.75, top_k=40, temperature=0.1)\n",
    "#     completion = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "#     completion = completion.replace(prompt, \"\").split(\"\\n\\n\\n\")[0]\n",
    "#     res=completion\n",
    "\n",
    "#     print('-----------------------text----------------')\n",
    "#     pprint(prompt)\n",
    "#     print('-------------------------res------------------')\n",
    "#     pprint(res)\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
