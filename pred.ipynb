{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"data/datafinal.json\"\n",
    "ftraind_path=\"data/f_traind.csv\"\n",
    "\n",
    "submission_path=\"data/submission.csv\"\n",
    "\n",
    "# vars\n",
    "col_text='Text'\n",
    "col_cc='ContainsCode'\n",
    "col_cl='CodeList'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                                             11\n",
       "Text            The field of software development is incredibl...\n",
       "ContainsCode                                                 True\n",
       "CodeList        #include <iostream> using namespace std; int m...\n",
       "Name: 10, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data=pd.read_json(data_path)\n",
    "ftrain_data=pd.read_csv(ftraind_path)\n",
    "train_data=full_data[full_data[col_cc]!=\"\"]\n",
    "test_data=full_data[full_data[col_cc]==\"\"]\n",
    "# pprint(train_data.iloc[1,1])\n",
    "train_data\n",
    "full_data.iloc[10]\n",
    "# full_data.to_csv(\"/home/u131168/mh_shell/data/datafinal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_dir='mh_shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in /opt/miniconda/lib/python3.10/site-packages (0.41.1)\n",
      "Requirement already satisfied: accelerate in /home/u131168/.local/lib/python3.10/site-packages (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/u131168/.local/lib/python3.10/site-packages (from accelerate) (1.26.0)\n",
      "Requirement already satisfied: huggingface-hub in /home/u131168/.local/lib/python3.10/site-packages (from accelerate) (0.16.4)\n",
      "Requirement already satisfied: pyyaml in /home/u131168/.local/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/u131168/.local/lib/python3.10/site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: psutil in /home/u131168/.local/lib/python3.10/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda/lib/python3.10/site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: filelock in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.4)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.101)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: networkx in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.7.91)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (65.6.3)\n",
      "Requirement already satisfied: wheel in /opt/miniconda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->accelerate) (0.38.4)\n",
      "Requirement already satisfied: cmake in /home/u131168/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.5)\n",
      "Requirement already satisfied: lit in /home/u131168/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
      "Requirement already satisfied: requests in /opt/miniconda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/miniconda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/u131168/.local/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/u131168/.local/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/miniconda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/u131168/.local/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: scipy in /opt/miniconda/lib/python3.10/site-packages (1.11.2)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /home/u131168/.local/lib/python3.10/site-packages (from scipy) (1.26.0)\n",
      "Requirement already satisfied: transformers in /home/u131168/.local/lib/python3.10/site-packages (4.34.0.dev0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/u131168/.local/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: requests in /opt/miniconda/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/u131168/.local/lib/python3.10/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/u131168/.local/lib/python3.10/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/u131168/.local/lib/python3.10/site-packages (from transformers) (0.14.0)\n",
      "Requirement already satisfied: filelock in /home/u131168/.local/lib/python3.10/site-packages (from transformers) (3.12.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/u131168/.local/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/u131168/.local/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: fsspec in /home/u131168/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/u131168/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: peft in /home/u131168/.local/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: accelerate in /home/u131168/.local/lib/python3.10/site-packages (from peft) (0.23.0)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda/lib/python3.10/site-packages (from peft) (4.65.0)\n",
      "Requirement already satisfied: pyyaml in /home/u131168/.local/lib/python3.10/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: safetensors in /home/u131168/.local/lib/python3.10/site-packages (from peft) (0.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda/lib/python3.10/site-packages (from peft) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/u131168/.local/lib/python3.10/site-packages (from peft) (1.26.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/u131168/.local/lib/python3.10/site-packages (from peft) (2.0.1)\n",
      "Requirement already satisfied: psutil in /home/u131168/.local/lib/python3.10/site-packages (from peft) (5.9.5)\n",
      "Requirement already satisfied: transformers in /home/u131168/.local/lib/python3.10/site-packages (from peft) (4.34.0.dev0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.4.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (2.0.0)\n",
      "Requirement already satisfied: networkx in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\n",
      "Requirement already satisfied: filelock in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (4.8.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.99)\n",
      "Requirement already satisfied: sympy in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: jinja2 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/u131168/.local/lib/python3.10/site-packages (from torch>=1.13.0->peft) (10.9.0.58)\n",
      "Requirement already satisfied: wheel in /opt/miniconda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft) (65.6.3)\n",
      "Requirement already satisfied: lit in /home/u131168/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13.0->peft) (16.0.6)\n",
      "Requirement already satisfied: cmake in /home/u131168/.local/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.13.0->peft) (3.27.5)\n",
      "Requirement already satisfied: huggingface-hub in /home/u131168/.local/lib/python3.10/site-packages (from accelerate->peft) (0.16.4)\n",
      "Requirement already satisfied: requests in /opt/miniconda/lib/python3.10/site-packages (from transformers->peft) (2.28.1)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/u131168/.local/lib/python3.10/site-packages (from transformers->peft) (0.14.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/u131168/.local/lib/python3.10/site-packages (from transformers->peft) (2023.8.8)\n",
      "Requirement already satisfied: fsspec in /home/u131168/.local/lib/python3.10/site-packages (from huggingface-hub->accelerate->peft) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/u131168/.local/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers->peft) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers->peft) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers->peft) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/miniconda/lib/python3.10/site-packages (from requests->transformers->peft) (2.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/u131168/.local/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes\n",
    "!pip install accelerate\n",
    "!pip install scipy\n",
    "!pip install transformers\n",
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2156d0bae4549318f2d79f7f93ab503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from peft import AutoPeftModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "# model_path=f\"/home/u131168/{mh_dir}/ft_models/flan-t5-xl_peft_finetuned_model/checkpoint-11700\"\n",
    "model_path=f\"/home/u131168/{mh_dir}/ft_models/flan-t5-xl_mt5/checkpoint-3200\"\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "custom_model = AutoPeftModelForSeq2SeqLM.from_pretrained(model_path, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# p_count=50\n",
    "psi,pei=58,68\n",
    "prompts = ftrain_data.loc[psi:pei,['input','instruction']].values.tolist()\n",
    "# instruction=\"extract code snippets from the paragraph, if it does not contain code snippets then say none\"\n",
    "\n",
    "t_prompts=[]\n",
    "for p in prompts:\n",
    "    context=str(p[0])\n",
    "    question=p[1]\n",
    "    t_prompts.append([context, question])\n",
    "    # t_prompts+=[f\"input: {context}\\n\\ninstruction: {question}\"]\n",
    "\n",
    "prompts=t_prompts\n",
    "# prompts = ftrain_data.loc[:p_count,['input','instruction']].values.tolist()\n",
    "# pprint(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import AddedToken\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "stokens=[]\n",
    "# stokens=[\"{\", \"}\" ,\"\\n\",\"<\", \">\",\" \",'\\\\','/','^']\n",
    "# for st in stokens:\n",
    "    # tokenizer.add_tokens(AddedToken(st, normalized=False))\n",
    "\n",
    "stokens=[\"`\",\"~\",\"!\",\"@\",\"#\",\"$\",\"%\",\"^\",\"&\",\"*\",\"(\",\")\",\"-\",\"_\",\"+\",\"=\",\"{\",\"}\",\"[\",\"]\",\"|\",\"\\\\\",\":\",\";\",\"\\\"\",\"'\",\"<\",\">\",\"?\",\"/\",\"\\n\",\" \"]\n",
    "for st in stokens:\n",
    "    tokenizer.add_tokens(AddedToken(st, normalized=False),special_tokens=False)\n",
    "\n",
    "# tokenizer.add_tokens(stokens,special_tokens=False)\n",
    "\n",
    "# custom_model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "input_ids = tokenizer(prompts, return_tensors=\"pt\" ,padding=True,truncation=True, max_length=512).input_ids\n",
    "# sample up to 30 tokens\n",
    "torch.manual_seed(0)  # doctest: +IGNORE_RESULT\n",
    "outputs = custom_model.generate(input_ids=input_ids, do_sample=True, max_length=100)\n",
    "# pred_custom=tokenizer.batch_decode(outputs, skip_special_tokens=False,spaces_between_special_tokens = False)\n",
    "pred_custom=tokenizer.batch_decode(outputs, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"int arr[5] = \\n\\\\{`~1,};:[ ]\\\\++++ - *&^%$#@!_+)'5>2,\"]\n",
      "[\"int arr[5] = \\n\\\\{`~1,};:[ ]\\\\++++ - *&^%$#@!_+)'5>2,\"]\n",
      "[\"int   arr [ 5 ]   =   \\n \\\\ { ` ~ 1, } ; : [   ] \\\\ + + + +   -   * & ^ % $ # @! _ + )'5 > 2,\"]\n"
     ]
    }
   ],
   "source": [
    "# # # !pip install transformers\n",
    "# # from transformers import AutoTokenizer\n",
    "# # from transformers import T5Tokenizer\n",
    "\n",
    "# # from tokenizers import AddedToken\n",
    "# text=\"int arr[5] = \\n\\{`~1,};:[ ]\\++++ - *&^%$#@!_+)'5>2,\"\n",
    "# # # text=\"int arr[5] = {1, 2, 3, 4, 5};', 'for(int i=0; i<5; i++) {cout << arr[i] << endl;}\"\n",
    "# # # text=\"function add(a, b) { \\n\\n<< return a + b; }\"\n",
    "\n",
    "# # # tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "# tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xl\")\n",
    "# # # tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# # stokens=[]\n",
    "# # stokens=[\"{\", \"}\" ,\"\\n\",\"<\",'\\\\','/','^',\" \",\"`\",\"~\"]\n",
    "# stokens=[\"`\",\"~\",\"!\",\"@\",\"#\",\"$\",\"%\",\"^\",\"&\",\"*\",\"(\",\")\",\"-\",\"_\",\"+\",\"=\",\"{\",\"}\",\"[\",\"]\",\"|\",\"\\\\\",\":\",\";\",\"\\\"\",\"'\",\"<\",\">\",\"?\",\"/\",\"\\n\",\" \"]\n",
    "# for st in stokens:\n",
    "#     tokenizer.add_tokens(AddedToken(st, normalized=False),special_tokens=False)\n",
    "\n",
    "# # # tokenizer.add_tokens([\"{\",\"}\",\"<\",\"\\n\"])\n",
    "# input_ids = tokenizer(text, return_tensors=\"pt\" ,padding=True,truncation=True, max_length=512).input_ids\n",
    "# # # pred_custom=tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "# print([text])\n",
    "# print(tokenizer.batch_decode(input_ids,skip_special_tokens=True,spaces_between_special_tokens = False))\n",
    "# print(tokenizer.batch_decode(input_ids,skip_special_tokens=True,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>input</th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "      <th>pred_custom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>paragraph:  In software development, debugging...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>int arr[5] = {1, 2, 3, 4, 5};', 'for(int i=0; ...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>paragraph:  Software developers are in high de...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>paragraph:  Developing software is a complex t...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>function add(a, b) { return a + b; }</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>paragraph:  Software development is a field th...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>paragraph:  Software development is a field th...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>63</td>\n",
       "      <td>paragraph:  When it comes to software developm...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>numbers = [5, 1, 9, 3, 7]; sorted_numbers = so...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>64</td>\n",
       "      <td>paragraph:  Software development is a multi-fa...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>#include &lt;iostream&gt;; int main() { std::cout &lt;&lt;...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>65</td>\n",
       "      <td>paragraph:  The world of software development ...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>66</td>\n",
       "      <td>paragraph:  Software development is an excitin...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>67</td>\n",
       "      <td>paragraph:  Software development is a fast-pac...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>function square(number) { return number * numb...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>68</td>\n",
       "      <td>paragraph:  In the realm of software developme...</td>\n",
       "      <td>extract code snippets from the paragraph, if i...</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                              input  \\\n",
       "0      58  paragraph:  In software development, debugging...   \n",
       "1      59  paragraph:  Software developers are in high de...   \n",
       "2      60  paragraph:  Developing software is a complex t...   \n",
       "3      61  paragraph:  Software development is a field th...   \n",
       "4      62  paragraph:  Software development is a field th...   \n",
       "5      63  paragraph:  When it comes to software developm...   \n",
       "6      64  paragraph:  Software development is a multi-fa...   \n",
       "7      65  paragraph:  The world of software development ...   \n",
       "8      66  paragraph:  Software development is an excitin...   \n",
       "9      67  paragraph:  Software development is a fast-pac...   \n",
       "10     68  paragraph:  In the realm of software developme...   \n",
       "\n",
       "                                          instruction  \\\n",
       "0   extract code snippets from the paragraph, if i...   \n",
       "1   extract code snippets from the paragraph, if i...   \n",
       "2   extract code snippets from the paragraph, if i...   \n",
       "3   extract code snippets from the paragraph, if i...   \n",
       "4   extract code snippets from the paragraph, if i...   \n",
       "5   extract code snippets from the paragraph, if i...   \n",
       "6   extract code snippets from the paragraph, if i...   \n",
       "7   extract code snippets from the paragraph, if i...   \n",
       "8   extract code snippets from the paragraph, if i...   \n",
       "9   extract code snippets from the paragraph, if i...   \n",
       "10  extract code snippets from the paragraph, if i...   \n",
       "\n",
       "                                               output pred_custom  \n",
       "0   int arr[5] = {1, 2, 3, 4, 5};', 'for(int i=0; ...        none  \n",
       "1                                                none        none  \n",
       "2                function add(a, b) { return a + b; }        none  \n",
       "3                                                none        none  \n",
       "4                                                none        none  \n",
       "5   numbers = [5, 1, 9, 3, 7]; sorted_numbers = so...        none  \n",
       "6   #include <iostream>; int main() { std::cout <<...        none  \n",
       "7                                                none        none  \n",
       "8                                                none        none  \n",
       "9   function square(number) { return number * numb...        none  \n",
       "10                                               none        none  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_custom_df=pd.DataFrame(pd.Series(pred_custom,name=\"pred_custom\"))\n",
    "# pred_ft5_df=pd.DataFrame(pd.Series(pred_ft5,name=\"pred_ft5\"))\n",
    "temp_df=pd.concat([ftrain_data.iloc[psi:pei+1].reset_index(),pred_custom_df],axis=1)\n",
    "temp_df\n",
    "# pprint(temp_df.iloc[1,0])\n",
    "# print(temp_df.iloc[0,3])\n",
    "# print(temp_df.iloc[0,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 8 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36977/4096530504.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtemp_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4002\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mCaller\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mresponsible\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchecking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4003\u001b[0m         \"\"\"\n\u001b[1;32m   4004\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4005\u001b[0m             \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4006\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4008\u001b[0m         \u001b[0mseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4009\u001b[0m         \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 8 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "temp_df.iloc[8,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Couldn't instantiate the backend tokenizer from one of: \n(1) a `tokenizers` library serialization file, \n(2) a slow tokenizer instance to convert or \n(3) an equivalent slow tokenizer class to instantiate and convert. \nYou need to have sentencepiece installed to convert a slow tokenizer to a fast one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/u131168/mh_shell/pred.ipynb Cell 5\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://tunnel%2Bmh_one_api/home/u131168/mh_shell/pred.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtransformers\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://tunnel%2Bmh_one_api/home/u131168/mh_shell/pred.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[0;32m----> <a href='vscode-notebook-cell://tunnel%2Bmh_one_api/home/u131168/mh_shell/pred.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(model, trust_remote_code\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://tunnel%2Bmh_one_api/home/u131168/mh_shell/pred.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForCausalLM\u001b[39m.\u001b[39mfrom_pretrained(model)\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Bmh_one_api/home/u131168/mh_shell/pred.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# from transformers import AutoTokenizer, LlamaForCausalLM\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Bmh_one_api/home/u131168/mh_shell/pred.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# model_path = \"Phind/Phind-CodeLlama-34B-v1\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Bmh_one_api/home/u131168/mh_shell/pred.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# model = LlamaForCausalLM.from_pretrained(model_path, device_map=\"auto\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://tunnel%2Bmh_one_api/home/u131168/mh_shell/pred.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# tokenizer = AutoTokenizer.from_pretrained(model_path)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:736\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[39mif\u001b[39;00m tokenizer_class \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    733\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    734\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTokenizer class \u001b[39m\u001b[39m{\u001b[39;00mtokenizer_class_candidate\u001b[39m}\u001b[39;00m\u001b[39m does not exist or is not currently imported.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    735\u001b[0m         )\n\u001b[0;32m--> 736\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer_class\u001b[39m.\u001b[39;49mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49minputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    738\u001b[0m \u001b[39m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[39m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(config, EncoderDecoderConfig):\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1854\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1851\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1852\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloading file \u001b[39m\u001b[39m{\u001b[39;00mfile_path\u001b[39m}\u001b[39;00m\u001b[39m from cache at \u001b[39m\u001b[39m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1854\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_from_pretrained(\n\u001b[1;32m   1855\u001b[0m     resolved_vocab_files,\n\u001b[1;32m   1856\u001b[0m     pretrained_model_name_or_path,\n\u001b[1;32m   1857\u001b[0m     init_configuration,\n\u001b[1;32m   1858\u001b[0m     \u001b[39m*\u001b[39;49minit_inputs,\n\u001b[1;32m   1859\u001b[0m     token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1860\u001b[0m     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m   1861\u001b[0m     local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m   1862\u001b[0m     _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[1;32m   1863\u001b[0m     _is_local\u001b[39m=\u001b[39;49mis_local,\n\u001b[1;32m   1864\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1865\u001b[0m )\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2017\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[0;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2015\u001b[0m \u001b[39m# Instantiate tokenizer.\u001b[39;00m\n\u001b[1;32m   2016\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2017\u001b[0m     tokenizer \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49minit_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49minit_kwargs)\n\u001b[1;32m   2018\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[1;32m   2019\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m   2020\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnable to load vocabulary from file. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2021\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease check that the provided vocabulary is accessible and not corrupted.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2022\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.10/site-packages/transformers/models/llama/tokenization_llama_fast.py:116\u001b[0m, in \u001b[0;36mLlamaTokenizerFast.__init__\u001b[0;34m(self, vocab_file, tokenizer_file, clean_up_tokenization_spaces, unk_token, bos_token, eos_token, add_bos_token, add_eos_token, use_default_system_prompt, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    104\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    105\u001b[0m     vocab_file\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    115\u001b[0m ):\n\u001b[0;32m--> 116\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    117\u001b[0m         vocab_file\u001b[39m=\u001b[39;49mvocab_file,\n\u001b[1;32m    118\u001b[0m         tokenizer_file\u001b[39m=\u001b[39;49mtokenizer_file,\n\u001b[1;32m    119\u001b[0m         clean_up_tokenization_spaces\u001b[39m=\u001b[39;49mclean_up_tokenization_spaces,\n\u001b[1;32m    120\u001b[0m         unk_token\u001b[39m=\u001b[39;49munk_token,\n\u001b[1;32m    121\u001b[0m         bos_token\u001b[39m=\u001b[39;49mbos_token,\n\u001b[1;32m    122\u001b[0m         eos_token\u001b[39m=\u001b[39;49meos_token,\n\u001b[1;32m    123\u001b[0m         use_default_system_prompt\u001b[39m=\u001b[39;49muse_default_system_prompt,\n\u001b[1;32m    124\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    125\u001b[0m     )\n\u001b[1;32m    126\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_bos_token \u001b[39m=\u001b[39m add_bos_token\n\u001b[1;32m    127\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_eos_token \u001b[39m=\u001b[39m add_eos_token\n",
      "File \u001b[0;32m/opt/miniconda/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:119\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     fast_tokenizer \u001b[39m=\u001b[39m convert_slow_tokenizer(slow_tokenizer)\n\u001b[1;32m    118\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    120\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt instantiate the backend tokenizer from one of: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(1) a `tokenizers` library serialization file, \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(2) a slow tokenizer instance to convert or \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(3) an equivalent slow tokenizer class to instantiate and convert. \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou need to have sentencepiece installed to convert a slow tokenizer to a fast one.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m     )\n\u001b[1;32m    127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tokenizer \u001b[39m=\u001b[39m fast_tokenizer\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m slow_tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Couldn't instantiate the backend tokenizer from one of: \n(1) a `tokenizers` library serialization file, \n(2) a slow tokenizer instance to convert or \n(3) an equivalent slow tokenizer class to instantiate and convert. \nYou need to have sentencepiece installed to convert a slow tokenizer to a fast one."
     ]
    }
   ],
   "source": [
    "# # !pip install tiktoken\n",
    "# # !pip install transformers\n",
    "# # model='Salesforce/codegen-350M-mono'\n",
    "# # model='Salesforce/codegen25-7b-instruct'\n",
    "# model=\"Phind/Phind-CodeLlama-34B-v1\"\n",
    "# import transformers\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model, trust_remote_code=True)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model)\n",
    "\n",
    "\n",
    "# # from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "# # model_path = \"Phind/Phind-CodeLlama-34B-v1\"\n",
    "# # model = LlamaForCausalLM.from_pretrained(model_path, device_map=\"auto\")\n",
    "# # tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------text----------------\n",
      "('extract code from the following paragraph:\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'DevOps is a set of practices that combines software development and IT '\n",
      " 'operations. It aims to shorten the system development life cycle and provide '\n",
      " 'continuous delivery with high software quality. DevOps is complementary with '\n",
      " 'Agile software development; several DevOps aspects came from Agile '\n",
      " 'methodology.')\n",
      "-------------------------res------------------\n",
      "('The problem is not a programming problem, but a text extraction problem. '\n",
      " 'Here is a simple Python script that extracts the code from the given '\n",
      " 'paragraph:\\n'\n",
      " '\\n'\n",
      " '```python\\n'\n",
      " 'paragraph = \"DevOps is a set of practices that combines software development '\n",
      " 'and IT operations. It aims to shorten the system development life cycle and '\n",
      " 'provide continuous delivery with high software quality. DevOps is '\n",
      " 'complementary with Agile software development; several DevOps aspects came '\n",
      " 'from Agile methodology.\"\\n'\n",
      " '\\n'\n",
      " 'code = []\\n'\n",
      " '\\n'\n",
      " 'for word in paragraph.split():\\n'\n",
      " \"    if word.startswith('DevOps') or word.startswith('Agile'):\\n\"\n",
      " '        code.append(word)\\n'\n",
      " '\\n'\n",
      " 'print(code)\\n'\n",
      " '```\\n'\n",
      " '\\n'\n",
      " 'This script will output:\\n'\n",
      " '\\n'\n",
      " '```python\\n'\n",
      " \"['DevOps', 'Agile']\\n\"\n",
      " '```\\n'\n",
      " '\\n'\n",
      " 'This is a very simple script and it assumes that the words \"DevOps\" and '\n",
      " '\"Agile\" are the only ones that could be considered as code in this context. '\n",
      " 'If there are other potential code words, they would need to be added to the '\n",
      " 'script.')\n"
     ]
    }
   ],
   "source": [
    "# from pprint import pprint\n",
    "# # creating prompts\n",
    "# prompts=[]\n",
    "# for i in train_data[124:125].index:\n",
    "#     prompt='extract code from the following paragraph:\\n\\n\\n'+train_data.iloc[i,1].replace('\\n','')\n",
    "    \n",
    "#     # predict\n",
    "#     # text = \"def hello_world():\"\n",
    "#     # text = prompt\n",
    "#     # input_ids = tokenizer(text, return_tensors=\"pt\").input_ids\n",
    "#     # generated_ids = model.generate(input_ids, max_length=128)\n",
    "#     # res=tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "#     tokenizer.pad_token = tokenizer.eos_token\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=4096)\n",
    "\n",
    "#     # Generate\n",
    "#     generate_ids = model.generate(inputs.input_ids, max_new_tokens=256, do_sample=True, top_p=0.75, top_k=40, temperature=0.1)\n",
    "#     completion = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
    "#     completion = completion.replace(prompt, \"\").split(\"\\n\\n\\n\")[0]\n",
    "#     res=completion\n",
    "\n",
    "#     print('-----------------------text----------------')\n",
    "#     pprint(prompt)\n",
    "#     print('-------------------------res------------------')\n",
    "#     pprint(res)\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
